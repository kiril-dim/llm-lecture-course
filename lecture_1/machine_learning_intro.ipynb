{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –õ–µ–∫—Ü–∏—è 1: –í—ä–≤–µ–¥–µ–Ω–∏–µ –≤ –ò–∑–∫—É—Å—Ç–≤–µ–Ω –ò–Ω—Ç–µ–ª–µ–∫—Ç –∏ –ú–∞—à–∏–Ω–Ω–æ –û–±—É—á–µ–Ω–∏–µ\n",
    "\n",
    "## –§–æ–∫—É—Å: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω –ï–∑–∏–∫ (NLP)\n",
    "\n",
    "**–ü—Ä–æ–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–æ—Å—Ç:** 2-2.5 —á–∞—Å–∞  \n",
    "**–°–ª–µ–¥–≤–∞—â–∞ –ª–µ–∫—Ü–∏—è:** –ï–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ –Ω–∞ –¥—É–º–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. –ú–æ—Ç–∏–≤–∞—Ü–∏—è: –ó–∞—â–æ AI –∏ ML –∑–∞ –µ–∑–∏–∫?\n",
    "\n",
    "### –ö–∞–∫–≤–æ –µ AI, ML –∏ NLP?\n",
    "\n",
    "**ü§ñ –ò–∑–∫—É—Å—Ç–≤–µ–Ω –ò–Ω—Ç–µ–ª–µ–∫—Ç (AI)**  \n",
    "–®–∏—Ä–æ–∫–∞ –æ–±–ª–∞—Å—Ç, –∫–æ—è—Ç–æ —Å–µ –∑–∞–Ω–∏–º–∞–≤–∞ —Å—ä—Å —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –∏–Ω—Ç–µ–ª–∏–≥–µ–Ω—Ç–Ω–∏ —Å–∏—Å—Ç–µ–º–∏, —Å–ø–æ—Å–æ–±–Ω–∏ –¥–∞ —Ä–µ—à–∞–≤–∞—Ç –∑–∞–¥–∞—á–∏, –∫–æ–∏—Ç–æ –∏–∑–∏—Å–∫–≤–∞—Ç —á–æ–≤–µ—à–∫–∞ –∏–Ω—Ç–µ–ª–∏–≥–µ–Ω—Ç–Ω–æ—Å—Ç.\n",
    "\n",
    "**üìä –ú–∞—à–∏–Ω–Ω–æ –û–±—É—á–µ–Ω–∏–µ (ML)**  \n",
    "–ü–æ–¥–æ–±–ª–∞—Å—Ç –Ω–∞ AI, –∫—ä–¥–µ—Ç–æ —Å–∏—Å—Ç–µ–º–∏—Ç–µ **—É—á–∞—Ç –æ—Ç –¥–∞–Ω–Ω–∏**, –≤–º–µ—Å—Ç–æ –¥–∞ –±—ä–¥–∞—Ç –ø—Ä–æ–≥—Ä–∞–º–∏—Ä–∞–Ω–∏ –µ–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω–æ.\n",
    "\n",
    "**üí¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω –ï–∑–∏–∫ (NLP)**  \n",
    "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ ML –∑–∞ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–∞–Ω–µ –∏ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —á–æ–≤–µ—à–∫–∏ –µ–∑–∏–∫.\n",
    "\n",
    "### –ó–∞—â–æ –µ–∑–∏–∫—ä—Ç –µ —Ç—Ä—É–¥–µ–Ω –∑–∞ –∫–æ–º–ø—é—Ç—Ä–∏—Ç–µ?\n",
    "\n",
    "1. **–ú–Ω–æ–≥–æ–∑–Ω–∞—á–Ω–æ—Å—Ç**: \"–ë–∞–Ω–∫–∞—Ç–∞ –µ –∑–∞—Ç–≤–æ—Ä–µ–Ω–∞\" (—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞ –∏–Ω—Å—Ç–∏—Ç—É—Ü–∏—è –∏–ª–∏ —Ä–µ—á–µ–Ω –±—Ä—è–≥?)\n",
    "2. **–ö–æ–Ω—Ç–µ–∫—Å—Ç**: \"–ß—É–≤—Å—Ç–≤–∞–º —Å–µ —Å–∏–Ω\" —Å—Ä–µ—â—É \"–ù–µ–±–µ—Ç–æ –µ —Å–∏–Ω—å–æ\"\n",
    "3. **–°–∞—Ä–∫–∞–∑—ä–º –∏ –∏—Ä–æ–Ω–∏—è**: \"–°—Ç—Ä–∞—Ö–æ—Ç–Ω–æ, –ø–∞–∫ –∑–∞–∫—ä—Å–Ω—è—Ö...\" üòí\n",
    "4. **–ù–µ—è—Å–Ω–æ—Å—Ç–∏**: \"–í–∏–¥—è—Ö —á–æ–≤–µ–∫ —Å —Ç–µ–ª–µ—Å–∫–æ–ø\" (–∫–æ–π –∏–º–∞ —Ç–µ–ª–µ—Å–∫–æ–ø–∞?)\n",
    "\n",
    "### –£—Å–ø–µ—à–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–∞ NLP\n",
    "\n",
    "‚úÖ **–ú–∞—à–∏–Ω–µ–Ω –ø—Ä–µ–≤–æ–¥**: Google Translate, DeepL  \n",
    "‚úÖ **–ß–∞—Ç–±–æ—Ç–æ–≤–µ**: ChatGPT, Claude, Siri  \n",
    "‚úÖ **–ê–Ω–∞–ª–∏–∑ –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è**: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–∞ —Å–æ—Ü–∏–∞–ª–Ω–∏ –º–µ–¥–∏–∏  \n",
    "‚úÖ **–û–±–æ–±—â–∞–≤–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç**: –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–µ–∑—é–º–µ—Ç–∞ –Ω–∞ —Å—Ç–∞—Ç–∏–∏  \n",
    "‚úÖ **–†–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ –Ω–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏ –æ–±–µ–∫—Ç–∏**: –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –∏–º–µ–Ω–∞, –º–µ—Å—Ç–∞, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. –§–æ—Ä–º—É–ª–∏—Ä–∞–Ω–µ –Ω–∞ ML –∑–∞–¥–∞—á–∞\n",
    "\n",
    "### –§–æ—Ä–º–∞–ª–Ω–∞ –¥–µ—Ñ–∏–Ω–∏—Ü–∏—è\n",
    "\n",
    "–í –º–∞—à–∏–Ω–Ω–æ—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–∫–∞–º–µ –¥–∞ –Ω–∞—É—á–∏–º —Ñ—É–Ω–∫—Ü–∏—è $h: \\mathcal{X} \\to \\mathcal{Y}$, –∫–æ—è—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞ –≤—Ö–æ–¥–æ–≤–µ –≤ –∏–∑—Ö–æ–¥–∏.\n",
    "\n",
    "**–ö–ª—é—á–æ–≤–∏ –ø–æ–Ω—è—Ç–∏—è:**\n",
    "- $\\mathcal{X}$: **–í—Ö–æ–¥–Ω–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ** (–Ω–∞–ø—Ä–∏–º–µ—Ä: —Ç–µ–∫—Å—Ç–æ–≤–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏, –∏–∑—Ä–µ—á–µ–Ω–∏—è, –¥—É–º–∏)\n",
    "- $\\mathcal{Y}$: **–ò–∑—Ö–æ–¥–Ω–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ** (–Ω–∞–ø—Ä–∏–º–µ—Ä: –µ—Ç–∏–∫–µ—Ç–∏, –ø—Ä–µ–≤–æ–¥–∏, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è)\n",
    "- $(x^{(i)}, y^{(i)})$: **–¢—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏ –ø—Ä–∏–º–µ—Ä–∏** (–≤—Ö–æ–¥–Ω–æ-–∏–∑—Ö–æ–¥–Ω–∏ –¥–≤–æ–π–∫–∏)\n",
    "- $h$: **–•–∏–ø–æ—Ç–µ–∑–∞/–ú–æ–¥–µ–ª** (—Ñ—É–Ω–∫—Ü–∏—è—Ç–∞, –∫–æ—è—Ç–æ —É—á–∏–º)\n",
    "\n",
    "### –ö–æ–Ω–∫—Ä–µ—Ç–µ–Ω NLP –ø—Ä–∏–º–µ—Ä: –ö–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ —Å–ø–∞–º –∏–º–µ–π–ª–∏\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞**: –û–ø—Ä–µ–¥–µ–ª–∏ –¥–∞–ª–∏ –∏–º–µ–π–ª –µ —Å–ø–∞–º –∏–ª–∏ –Ω–µ.\n",
    "\n",
    "- **–í—Ö–æ–¥** ($x$): –¢–µ–∫—Å—Ç—ä—Ç –Ω–∞ –∏–º–µ–π–ª–∞\n",
    "- **–ò–∑—Ö–æ–¥** ($y$): {\"—Å–ø–∞–º\", \"–Ω–µ –µ —Å–ø–∞–º\"}\n",
    "- **–û–±—É—á–µ–Ω–∏–µ**: –ò–∑–ø–æ–ª–∑–≤–∞–º–µ —Ö–∏–ª—è–¥–∏ –µ—Ç–∏–∫–µ—Ç–∏—Ä–∞–Ω–∏ –∏–º–µ–π–ª–∏\n",
    "- **–¶–µ–ª**: –ú–æ–¥–µ–ª—ä—Ç –¥–∞ –º–æ–∂–µ –¥–∞ –∫–ª–∞—Å–∏—Ñ–∏—Ü–∏—Ä–∞ –Ω–æ–≤–∏, –Ω–µ–≤–∏–∂–¥–∞–Ω–∏ –∏–º–µ–π–ª–∏\n",
    "\n",
    "**–ö–∞–∫–≤–æ –æ–∑–Ω–∞—á–∞–≤–∞ \"—É—á–µ–Ω–µ\" —Ç—É–∫?**  \n",
    "–ú–æ–¥–µ–ª—ä—Ç –æ—Ç–∫—Ä–∏–≤–∞ –º–æ–¥–µ–ª–∏ –≤ —Ç–µ–∫—Å—Ç–∞ (–¥—É–º–∏ –∫–∞—Ç–æ \"—Å–ø–µ—á–µ–ª–∏\", \"–±–µ–∑–ø–ª–∞—Ç–Ω–æ\", –º–Ω–æ–≥–æ —É–¥–∏–≤–∏—Ç–µ–ª–Ω–∏) –∫–æ–∏—Ç–æ –∫–æ—Ä–µ–ª–∏—Ä–∞—Ç —Å—ä—Å —Å–ø–∞–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. –û—Å–Ω–æ–≤–Ω–∞ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è —Å —Ç–µ–∫—Å—Ç–æ–≤–∏ –¥–∞–Ω–Ω–∏\n",
    "\n",
    "### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (Features) –≤ NLP\n",
    "\n",
    "–ó–∞ –¥–∞ –æ–±—Ä–∞–±–æ—Ç–≤–∞–º–µ —Ç–µ–∫—Å—Ç, —Ç—Ä—è–±–≤–∞ –¥–∞ –≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–º –∫–∞—Ç–æ —á–∏—Å–ª–∞. –ï—Ç–æ –Ω—è–∫–æ–ª–∫–æ –Ω–∞—á–∏–Ω–∞:\n",
    "\n",
    "#### 1. –ß–∞–Ω—Ç–∞ —Å –¥—É–º–∏ (Bag of Words)\n",
    "–ë—Ä–æ–∏–º –∫–æ–ª–∫–æ –ø—ä—Ç–∏ —Å–µ –ø–æ—è–≤—è–≤–∞ –≤—Å—è–∫–∞ –¥—É–º–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –∏–≥–Ω–æ—Ä–∏—Ä–∞–π–∫–∏ —Ä–µ–¥–∞.\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä:**\n",
    "- –ò–∑—Ä–µ—á–µ–Ω–∏–µ: \"–•–∞—Ä–µ—Å–≤–∞–º —Ç–æ–∑–∏ —Ñ–∏–ª–º. –¢–æ–∑–∏ —Ñ–∏–ª–º –µ —Å—Ç—Ä–∞—Ö–æ—Ç–µ–Ω!\"\n",
    "- –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {\"—Ö–∞—Ä–µ—Å–≤–∞–º\": 1, \"—Ç–æ–∑–∏\": 2, \"—Ñ–∏–ª–º\": 2, \"–µ\": 1, \"—Å—Ç—Ä–∞—Ö–æ—Ç–µ–Ω\": 1}\n",
    "\n",
    "#### 2. TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "–ü–æ-—É–º–Ω–∞ —Å—Ö–µ–º–∞ –∑–∞ –ø—Ä–µ—Ç–µ–≥–ª—è–Ω–µ: —á–µ—Å—Ç–æ —Å—Ä–µ—â–∞–Ω–∏ –¥—É–º–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –Ω–æ —Ä–µ–¥–∫–∏ –≤ –∫–æ—Ä–ø—É—Å–∞, –ø–æ–ª—É—á–∞–≤–∞—Ç –≤–∏—Å–æ–∫–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç.\n",
    "\n",
    "#### 3. N-–≥—Ä–∞–º–∏\n",
    "–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ—Å—Ç–∏ –æ—Ç N –¥—É–º–∏:\n",
    "- –£–Ω–∏-–≥—Ä–∞–º–∏: [\"—Ö–∞—Ä–µ—Å–≤–∞–º\", \"—Ç–æ–∑–∏\", \"—Ñ–∏–ª–º\"]\n",
    "- –ë–∏-–≥—Ä–∞–º–∏: [\"—Ö–∞—Ä–µ—Å–≤–∞–º —Ç–æ–∑–∏\", \"—Ç–æ–∑–∏ —Ñ–∏–ª–º\"]\n",
    "- –¢—Ä–∏-–≥—Ä–∞–º–∏: [\"—Ö–∞—Ä–µ—Å–≤–∞–º —Ç–æ–∑–∏ —Ñ–∏–ª–º\", \"—Ç–æ–∑–∏ —Ñ–∏–ª–º –µ\"]\n",
    "\n",
    "### –ï—Ç–∏–∫–µ—Ç–∏ (Labels)\n",
    "- **–ö–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è**: {–ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ, –Ω–µ—É—Ç—Ä–∞–ª–Ω–æ}\n",
    "- **–†–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ –Ω–∞ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏ –æ–±–µ–∫—Ç–∏**: {–ª–∏—Ü–µ, –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ, ...}\n",
    "- **–°–ª–µ–¥–≤–∞—â–∞ –¥—É–º–∞**: –í –µ–∑–∏–∫–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–≤–∞–º–µ —Å–ª–µ–¥–≤–∞—â–∞—Ç–∞ –¥—É–º–∞\n",
    "\n",
    "### –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ\n",
    "- **–¢—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–µ–Ω –Ω–∞–±–æ—Ä (70-80%)**: –ú–æ–¥–µ–ª—ä—Ç —É—á–∏ –æ—Ç —Ç–µ–∑–∏ –¥–∞–Ω–Ω–∏\n",
    "- **–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–µ–Ω –Ω–∞–±–æ—Ä (10-15%)**: –ù–∞—Å—Ç—Ä–æ–π–≤–∞–º–µ —Ö–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∏\n",
    "- **–¢–µ—Å—Ç–æ–≤ –Ω–∞–±–æ—Ä (10-15%)**: –§–∏–Ω–∞–ª–Ω–∞ –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –º–æ–¥–µ–ª–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ù–µ–∫–∞ –¥–∞ –≤–∏–¥–∏–º —Ç–æ–≤–∞ –≤ –¥–µ–π—Å—Ç–≤–∏–µ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏—Ç–µ\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì –í—Å–∏—á–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Å–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏ —É—Å–ø–µ—à–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è: Bag of Words –∏ TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏\n",
    "documents = [\n",
    "    \"–•–∞—Ä–µ—Å–≤–∞–º —Ç–æ–∑–∏ —Ñ–∏–ª–º. –¢–æ–∑–∏ —Ñ–∏–ª–º –µ —Å—Ç—Ä–∞—Ö–æ—Ç–µ–Ω!\",\n",
    "    \"–ù–µ —Ö–∞—Ä–µ—Å–≤–∞–º —Ç–æ–∑–∏ —Ñ–∏–ª–º. –§–∏–ª–º—ä—Ç –µ —É–∂–∞—Å–µ–Ω.\",\n",
    "    \"–¢–æ–∑–∏ —Ñ–∏–ª–º –µ –¥–æ–±—ä—Ä. –ü—Ä–µ–ø–æ—Ä—ä—á–≤–∞–º –≥–æ.\",\n",
    "    \"–§–∏–ª–º—ä—Ç –±–µ—à–µ —Å–∫—É—á–µ–Ω –∏ –¥—ä–ª—ä–≥.\"\n",
    "]\n",
    "\n",
    "print(\"üìÑ –ù–∞—à–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏:\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "# Bag of Words\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéí BAG OF WORDS –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vectorizer_bow = CountVectorizer()\n",
    "bow_matrix = vectorizer_bow.fit_transform(documents)\n",
    "\n",
    "# –ü–æ–∫–∞–∑–≤–∞–º–µ —Ä–µ—á–Ω–∏–∫–∞\n",
    "vocab = vectorizer_bow.get_feature_names_out()\n",
    "print(f\"\\n–†–µ—á–Ω–∏–∫ ({len(vocab)} —É–Ω–∏–∫–∞–ª–Ω–∏ –¥—É–º–∏):\")\n",
    "print(vocab)\n",
    "\n",
    "# –ü–æ–∫–∞–∑–≤–∞–º–µ –º–∞—Ç—Ä–∏—Ü–∞—Ç–∞\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vocab)\n",
    "print(\"\\n–ú–∞—Ç—Ä–∏—Ü–∞ –¥–æ–∫—É–º–µ–Ω—Ç-—Ç–µ—Ä–º–∏–Ω (Bag of Words):\")\n",
    "print(bow_df)\n",
    "\n",
    "# TF-IDF\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TF-IDF –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(documents)\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vocab)\n",
    "print(\"\\n–ú–∞—Ç—Ä–∏—Ü–∞ –¥–æ–∫—É–º–µ–Ω—Ç-—Ç–µ—Ä–º–∏–Ω (TF-IDF):\")\n",
    "print(tfidf_df.round(3))\n",
    "\n",
    "print(\"\\nüí° –ó–∞–±–µ–ª–µ–∂–∫–∞: –í TF-IDF —á–µ—Å—Ç–æ —Å—Ä–µ—â–∞–Ω–∏—Ç–µ –¥—É–º–∏ (–∫–∞—Ç–æ '—Ñ–∏–ª–º') –ø–æ–ª—É—á–∞–≤–∞—Ç –ø–æ-–Ω–∏—Å–∫–∏ —Ç–µ–≥–ª–∞,\")\n",
    "print(\"   –¥–æ–∫–∞—Ç–æ –ø–æ-—Ä—è–¥–∫–æ —Å—Ä–µ—â–∞–Ω–∏—Ç–µ –¥—É–º–∏ (–∫–∞—Ç–æ '–ø—Ä–µ–ø–æ—Ä—ä—á–≤–∞–º') –ø–æ–ª—É—á–∞–≤–∞—Ç –ø–æ-–≤–∏—Å–æ–∫–∏ —Ç–µ–≥–ª–∞.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. –ü–∞—Ä–∞–¥–∏–≥–º–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ —Å NLP –ø—Ä–∏–º–µ—Ä–∏\n",
    "\n",
    "### 4.1 –û–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª (Supervised Learning)\n",
    "\n",
    "–ò–º–∞–º–µ **–µ—Ç–∏–∫–µ—Ç–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏** –∏ –∏—Å–∫–∞–º–µ –¥–∞ –Ω–∞—É—á–∏–º –º–æ–¥–µ–ª –¥–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–≤–∞ –µ—Ç–∏–∫–µ—Ç–∏ –∑–∞ –Ω–æ–≤–∏ –¥–∞–Ω–Ω–∏.\n",
    "\n",
    "#### –ü—Ä–∏–º–µ—Ä: –ê–Ω–∞–ª–∏–∑ –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (Sentiment Analysis)\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞**: –û–ø—Ä–µ–¥–µ–ª–∏ –¥–∞–ª–∏ —Ä–µ–≤—é—Ç–æ –Ω–∞ —Ñ–∏–ª–º –µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–∞–ª—ä–∫ dataset –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è\n",
    "# –í —Ä–µ–∞–ª–Ω–∞—Ç–∞ –ø—Ä–∞–∫—Ç–∏–∫–∞ –±–∏—Ö–º–µ –∏–∑–ø–æ–ª–∑–≤–∞–ª–∏ IMDB dataset —Å 50,000 —Ä–µ–≤—é—Ç–∞\n",
    "\n",
    "texts = [\n",
    "    \"–¢–æ–∑–∏ —Ñ–∏–ª–º –µ —Å—Ç—Ä–∞—Ö–æ—Ç–µ–Ω! –ú–Ω–æ–≥–æ –º–∏ —Ö–∞—Ä–µ—Å–∞.\",\n",
    "    \"–ù–∞–π-–¥–æ–±—Ä–∏—è—Ç —Ñ–∏–ª–º, –∫–æ–π—Ç–æ —Å—ä–º –≥–ª–µ–¥–∞–ª!\",\n",
    "    \"–ü–µ—Ä—Ñ–µ–∫—Ç–Ω–æ! –ü—Ä–µ–ø–æ—Ä—ä—á–≤–∞–º –Ω–∞ –≤—Å–∏—á–∫–∏.\",\n",
    "    \"–ß—É–¥–µ—Å–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è –∏ –æ—Ç–ª–∏—á–Ω–∏ –∞–∫—Ç—å–æ—Ä–∏.\",\n",
    "    \"–ü—Ä–µ–∫—Ä–∞—Å–µ–Ω —Ñ–∏–ª–º —Å –º–Ω–æ–≥–æ –µ–º–æ—Ü–∏–∏.\",\n",
    "    \"–£–∂–∞—Å–µ–Ω —Ñ–∏–ª–º. –ü—ä–ª–Ω–∞ –∑–∞–≥—É–±–∞ –Ω–∞ –≤—Ä–µ–º–µ.\",\n",
    "    \"–ù–∞–π-–ª–æ—à–∏—è—Ç —Ñ–∏–ª–º –Ω—è–∫–æ–≥–∞. –ò–∑–±—è–≥–≤–∞–π—Ç–µ –≥–æ.\",\n",
    "    \"–°–∫—É—á–µ–Ω –∏ –±–µ–∑–∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω. –ù–µ –≥–æ –ø—Ä–µ–ø–æ—Ä—ä—á–≤–∞–º.\",\n",
    "    \"–†–∞–∑–æ—á–∞—Ä–æ–≤–∞—â. –û—á–∞–∫–≤–∞—Ö –º–Ω–æ–≥–æ –ø–æ–≤–µ—á–µ.\",\n",
    "    \"–õ–æ—à —Å—Ü–µ–Ω–∞—Ä–∏–π –∏ —Å–ª–∞–±–∏ –∞–∫—Ç—å–æ—Ä–∏.\",\n",
    "    \"–ò–Ω—Ç–µ—Ä–µ—Å–µ–Ω —Ñ–∏–ª–º —Å –¥–æ–±—Ä–∞ —Ä–µ–∂–∏—Å—É—Ä–∞.\",\n",
    "    \"–•–∞—Ä–µ—Å–∞—Ö –∞–∫—Ç—å–æ—Ä—Å–∫–∞—Ç–∞ –∏–≥—Ä–∞.\",\n",
    "    \"–°—Ç—Ä–∞—Ö–æ—Ç–Ω–∏ —Å–ø–µ—Ü–µ—Ñ–µ–∫—Ç–∏ –∏ –µ–∫—à—ä–Ω.\",\n",
    "    \"–í–ø–µ—á–∞—Ç–ª—è–≤–∞—â —Ñ–∏–ª–º! –ó–∞—Å–ª—É–∂–∞–≤–∞ –≥–ª–µ–¥–∞–Ω–µ.\",\n",
    "    \"–ù–µ –µ –ª–æ—à, –Ω–æ –∏ –Ω–µ –µ —Å—Ç—Ä–∞—Ö–æ—Ç–µ–Ω.\"\n",
    "]\n",
    "\n",
    "# –ï—Ç–∏–∫–µ—Ç–∏: 1 = –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ, 0 = –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ\n",
    "labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
    "\n",
    "print(\"üìä Dataset –∑–∞ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è\")\n",
    "print(f\"–û–±—â–æ –ø—Ä–∏–º–µ—Ä–∏: {len(texts)}\")\n",
    "print(f\"–ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏: {sum(labels)} | –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–∏: {len(labels) - sum(labels)}\")\n",
    "print(\"\\n–ü—Ä–∏–º–µ—Ä–∏:\")\n",
    "for i in range(3):\n",
    "    sentiment = \"üòä –ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ\" if labels[i] == 1 else \"üòû –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ\"\n",
    "    print(f\"{sentiment}: '{texts[i]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–µ–Ω –∏ —Ç–µ—Å—Ç–æ–≤ –Ω–∞–±–æ—Ä\n",
    "\n",
    "**–í–∞–∂–Ω–æ**: –í–∏–Ω–∞–≥–∏ —Ä–∞–∑–¥–µ–ª—è–º–µ –¥–∞–Ω–Ω–∏—Ç–µ –ø—Ä–µ–¥–∏ –¥–∞ –æ–±—É—á–∏–º –º–æ–¥–µ–ª!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª—è–Ω–µ: 80% —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–µ–Ω, 20% —Ç–µ—Å—Ç–æ–≤\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(\"üîÑ –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ:\")\n",
    "print(f\"–¢—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–µ–Ω –Ω–∞–±–æ—Ä: {len(X_train)} –ø—Ä–∏–º–µ—Ä–∞\")\n",
    "print(f\"–¢–µ—Å—Ç–æ–≤ –Ω–∞–±–æ—Ä: {len(X_test)} –ø—Ä–∏–º–µ—Ä–∞\")\n",
    "print(f\"\\n‚úì –ò–∑–ø–æ–ª–∑–≤–∞–º–µ stratify –∑–∞ –¥–∞ –∑–∞–ø–∞–∑–∏–º –±–∞–ª–∞–Ω—Å–∞ –Ω–∞ –∫–ª–∞—Å–æ–≤–µ—Ç–µ –≤ –¥–≤–∞—Ç–∞ –Ω–∞–±–æ—Ä–∞.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç—ä–ø–∫–∞ 1: –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞ (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"üìê –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\")\n",
    "print(f\"–§–æ—Ä–º–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏: {X_train_vec.shape}\")\n",
    "print(f\"  ({X_train_vec.shape[0]} –¥–æ–∫—É–º–µ–Ω—Ç–∞, {X_train_vec.shape[1]} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)\")\n",
    "\n",
    "# –°—Ç—ä–ø–∫–∞ 2: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–ª–∞—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (Logistic Regression)\n",
    "model = LogisticRegression(random_state=42, max_iter=200)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "print(\"\\n‚úì –ú–æ–¥–µ–ª—ä—Ç –µ –æ–±—É—á–µ–Ω!\")\n",
    "\n",
    "# –°—Ç—ä–ø–∫–∞ 3: –ü—Ä–µ–¥—Å–∫–∞–∑–≤–∞–Ω–µ\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "# –°—Ç—ä–ø–∫–∞ 4: –û—Ü–µ–Ω–∫–∞\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nüéØ –¢–æ—á–Ω–æ—Å—Ç –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—è –Ω–∞–±–æ—Ä: {accuracy:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ù–µ–∫–∞ –¥–∞ —Ç–µ—Å—Ç–≤–∞–º–µ –º–æ–¥–µ–ª–∞ —Å –Ω–æ–≤–∏ —Ç–µ–∫—Å—Ç–æ–≤–µ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ù–æ–≤–∏ –ø—Ä–∏–º–µ—Ä–∏ –∑–∞ —Ç–µ—Å—Ç–≤–∞–Ω–µ\n",
    "new_reviews = [\n",
    "    \"–í–µ–ª–∏–∫–æ–ª–µ–ø–µ–Ω —Ñ–∏–ª–º! –©–µ –≥–æ –≥–ª–µ–¥–∞–º –æ—Ç–Ω–æ–≤–æ.\",\n",
    "    \"–£–∂–∞—Å–Ω–æ. –°—ä–∂–∞–ª—è–≤–∞–º —á–µ –ø–æ—Ö–∞—Ä—á–∏—Ö –ø–∞—Ä–∏ –∑–∞ –±–∏–ª–µ—Ç.\",\n",
    "    \"–î–æ–±—ä—Ä —Ñ–∏–ª–º, –Ω–æ –º–æ–∂–µ—à–µ –¥–∞ –±—ä–¥–µ –ø–æ-–¥–æ–±—ä—Ä.\"\n",
    "]\n",
    "\n",
    "print(\"üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ—Ç–æ –Ω–∞ –Ω–æ–≤–∏ —Ä–µ–≤—é—Ç–∞:\\n\")\n",
    "\n",
    "for review in new_reviews:\n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "    review_vec = vectorizer.transform([review])\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–≤–∞–Ω–µ\n",
    "    prediction = model.predict(review_vec)[0]\n",
    "    probability = model.predict_proba(review_vec)[0]\n",
    "    \n",
    "    sentiment = \"üòä –ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ\" if prediction == 1 else \"üòû –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ\"\n",
    "    confidence = max(probability) * 100\n",
    "    \n",
    "    print(f\"–†–µ–≤—é: '{review}'\")\n",
    "    print(f\"  ‚Üí –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {sentiment} (–£–≤–µ—Ä–µ–Ω–æ—Å—Ç: {confidence:.1f}%)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ê–Ω–∞–ª–∏–∑: –ö–æ–∏ –¥—É–º–∏ —Å–∞ –Ω–∞–π-–≤–∞–∂–Ω–∏?\n",
    "\n",
    "–ù–µ–∫–∞ –¥–∞ –≤–∏–¥–∏–º –∫–æ–∏ –¥—É–º–∏ –º–æ–¥–µ–ª—ä—Ç —Å—á–∏—Ç–∞ –∑–∞ –Ω–∞–π-–ø–æ–∫–∞–∑–∞—Ç–µ–ª–Ω–∏ –∑–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏ –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ –∫–æ–µ—Ñ–∏—Ü–∏–µ–Ω—Ç–∏—Ç–µ –Ω–∞ –º–æ–¥–µ–ª–∞\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä–∞–Ω–µ\n",
    "top_positive_idx = np.argsort(coefficients)[-10:]\n",
    "top_negative_idx = np.argsort(coefficients)[:10]\n",
    "\n",
    "print(\"üìà –¢–æ–ø 10 –¥—É–º–∏ –∑–∞ –ü–û–õ–û–ñ–ò–¢–ï–õ–ù–û –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ:\")\n",
    "for idx in reversed(top_positive_idx):\n",
    "    print(f\"  ‚Ä¢ {feature_names[idx]}: {coefficients[idx]:.3f}\")\n",
    "\n",
    "print(\"\\nüìâ –¢–æ–ø 10 –¥—É–º–∏ –∑–∞ –û–¢–†–ò–¶–ê–¢–ï–õ–ù–û –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ:\")\n",
    "for idx in top_negative_idx:\n",
    "    print(f\"  ‚Ä¢ {feature_names[idx]}: {coefficients[idx]:.3f}\")\n",
    "\n",
    "print(\"\\nüí° –ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏—Ç–µ –∫–æ–µ—Ñ–∏—Ü–∏–µ–Ω—Ç–∏ –ø–æ–∫–∞–∑–≤–∞—Ç –¥—É–º–∏, —Å–≤—ä—Ä–∑–∞–Ω–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ.\")\n",
    "print(\"   –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–∏—Ç–µ –∫–æ–µ—Ñ–∏—Ü–∏–µ–Ω—Ç–∏ –ø–æ–∫–∞–∑–≤–∞—Ç –¥—É–º–∏, —Å–≤—ä—Ä–∑–∞–Ω–∏ —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2 –û–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª (Unsupervised Learning)\n",
    "\n",
    "–ù—è–º–∞–º–µ –µ—Ç–∏–∫–µ—Ç–∏. –¶–µ–ª—Ç–∞ –µ –¥–∞ –æ—Ç–∫—Ä–∏–µ–º **—Å–∫—Ä–∏—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏** –≤ –¥–∞–Ω–Ω–∏—Ç–µ.\n",
    "\n",
    "### –ü—Ä–∏–º–µ—Ä: –ì—Ä—É–ø–∏—Ä–∞–Ω–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∏ (Document Clustering)\n",
    "\n",
    "–ü—Ä–µ–¥—Å—Ç–∞–≤–µ—Ç–µ —Å–∏, —á–µ –∏–º–∞–º–µ –Ω–æ–≤–∏–Ω–∞—Ä—Å–∫–∏ —Å—Ç–∞—Ç–∏–∏ –∏ –∏—Å–∫–∞–º–µ –¥–∞ –≥–∏ –≥—Ä—É–ø–∏—Ä–∞–º–µ –ø–æ —Ç–µ–º–∏, –±–µ–∑ –¥–∞ –∑–Ω–∞–µ–º —Ç–µ–º–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–ª–µ–∫—Ü–∏—è –æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–∏ —Ç–µ–º–∏\n",
    "news_articles = [\n",
    "    # –°–ø–æ—Ä—Ç\n",
    "    \"–õ–µ–≤—Å–∫–∏ –ø–æ–±–µ–¥–∏ –¶–°–ö–ê —Å 2:0 –≤ –¥–µ—Ä–±–∏—Ç–æ –Ω–∞ –°–æ—Ñ–∏—è.\",\n",
    "    \"–ì—Ä–∏–≥–æ—Ä –î–∏–º–∏—Ç—Ä–æ–≤ –¥–æ—Å—Ç–∏–≥–Ω–∞ –¥–æ —Ñ–∏–Ω–∞–ª–∞ –Ω–∞ —Ç—É—Ä–Ω–∏—Ä–∞ –≤ –õ–æ–Ω–¥–æ–Ω.\",\n",
    "    \"–ë—ä–ª–≥–∞—Ä—Å–∫–∏—è—Ç –Ω–∞—Ü–∏–æ–Ω–∞–ª–µ–Ω –æ—Ç–±–æ—Ä —Å–ø–µ—á–µ–ª–∏ –º–∞—á–∞ —Å—Ä–µ—â—É –®–≤–µ–π—Ü–∞—Ä–∏—è.\",\n",
    "    \"–†–æ–Ω–∞–ª–¥–æ –≤–∫–∞—Ä–∞ –¥–≤–∞ –≥–æ–ª–∞ –≤—ä–≤ –≤—á–µ—Ä–∞—à–Ω–∏—è –º–∞—á.\",\n",
    "    \n",
    "    # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏\n",
    "    \"Apple –ø—Ä–µ–¥—Å—Ç–∞–≤–∏ –Ω–æ–≤–∏—è iPhone —Å –ø–æ–¥–æ–±—Ä–µ–Ω–∞ –∫–∞–º–µ—Ä–∞ –∏ –±–∞—Ç–µ—Ä–∏—è.\",\n",
    "    \"–ò–∑–∫—É—Å—Ç–≤–µ–Ω–∏—è—Ç –∏–Ω—Ç–µ–ª–µ–∫—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–∏–∑–∏—Ä–∞ –∑–¥—Ä–∞–≤–µ–æ–ø–∞–∑–≤–∞–Ω–µ—Ç–æ.\",\n",
    "    \"Tesla –ø—É—Å–Ω–∞ –Ω–æ–≤–∞ –≤–µ—Ä—Å–∏—è –Ω–∞ –∞–≤—Ç–æ–ø–∏–ª–æ—Ç–∞ –∑–∞ —Å–≤–æ–∏—Ç–µ –∞–≤—Ç–æ–º–æ–±–∏–ª–∏.\",\n",
    "    \"Google —Ä–∞–∑—Ä–∞–±–æ—Ç–≤–∞ –Ω–æ–≤ –∫–≤–∞–Ω—Ç–æ–≤ –∫–æ–º–ø—é—Ç—ä—Ä.\",\n",
    "    \n",
    "    # –ü–æ–ª–∏—Ç–∏–∫–∞\n",
    "    \"–ü—Ä–µ–º–∏–µ—Ä—ä—Ç –æ–±—è–≤–∏ –Ω–æ–≤–∏ –º–µ—Ä–∫–∏ –∑–∞ –∏–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ —Ä–∞–∑–≤–∏—Ç–∏–µ.\",\n",
    "    \"–ü–∞—Ä–ª–∞–º–µ–Ω—Ç—ä—Ç –ø—Ä–∏–µ –∑–∞–∫–æ–Ω –∑–∞ —Ä–µ—Ñ–æ—Ä–º–∞ –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ—Ç–æ.\",\n",
    "    \"–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç—ä—Ç —É—á–∞—Å—Ç–≤–∞ –≤ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞ —Å—Ä–µ—â–∞ –≤ –ë—Ä—é–∫—Å–µ–ª.\",\n",
    "    \"–ù–æ–≤–∏—è—Ç –±—é–¥–∂–µ—Ç –±–µ—à–µ –æ–¥–æ–±—Ä–µ–Ω —Å–ª–µ–¥ –¥—ä–ª–≥–∏ –¥–µ–±–∞—Ç–∏.\"\n",
    "]\n",
    "\n",
    "print(\"üì∞ –ù–æ–≤–∏–Ω–∞—Ä—Å–∫–∏ —Å—Ç–∞—Ç–∏–∏ –∑–∞ –≥—Ä—É–ø–∏—Ä–∞–Ω–µ:\")\n",
    "for i, article in enumerate(news_articles, 1):\n",
    "    print(f\"{i}. {article}\")\n",
    "\n",
    "print(f\"\\nüí° –ò–º–∞–º–µ {len(news_articles)} —Å—Ç–∞—Ç–∏–∏. –ú–æ–∂–µ–º –ª–∏ –¥–∞ –≥–∏ –≥—Ä—É–ø–∏—Ä–∞–º–µ –ø–æ —Ç–µ–º–∏?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ç—ä–ø–∫–∞ 1: –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–Ω–µ –≤ TF-IDF –≤–µ–∫—Ç–æ—Ä–∏\n",
    "vectorizer_cluster = TfidfVectorizer(max_features=50)\n",
    "article_vectors = vectorizer_cluster.fit_transform(news_articles)\n",
    "\n",
    "print(\"üìä –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞:\")\n",
    "print(f\"–§–æ—Ä–º–∞ –Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞—Ç–∞: {article_vectors.shape}\")\n",
    "\n",
    "# –°—Ç—ä–ø–∫–∞ 2: –ü—Ä–∏–ª–∞–≥–∞–Ω–µ –Ω–∞ K-Means –∫–ª—ä—Å—Ç–µ—Ä–∏—Ä–∞–Ω–µ\n",
    "# –ö–∞–∑–≤–∞–º–µ –Ω–∞ –∞–ª–≥–æ—Ä–∏—Ç—ä–º–∞ –¥–∞ –Ω–∞–º–µ—Ä–∏ 3 –≥—Ä—É–ø–∏ (–∑–∞—â–æ—Ç–æ –∑–Ω–∞–µ–º, —á–µ –∏–º–∞ 3 —Ç–µ–º–∏)\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(article_vectors)\n",
    "\n",
    "print(f\"\\n‚úì –ö–ª—ä—Å—Ç–µ—Ä–∏—Ä–∞–Ω–µ—Ç–æ –µ –∑–∞–≤—ä—Ä—à–µ–Ω–æ! –û—Ç–∫—Ä–∏—Ç–∏ {n_clusters} –≥—Ä—É–ø–∏.\")\n",
    "\n",
    "# –ü–æ–∫–∞–∑–≤–∞–º–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìë –†–ï–ó–£–õ–¢–ê–¢–ò –û–¢ –ì–†–£–ü–ò–†–ê–ù–ï–¢–û\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for cluster_id in range(n_clusters):\n",
    "    print(f\"\\nüè∑Ô∏è  –ì–†–£–ü–ê {cluster_id}:\")\n",
    "    indices = np.where(clusters == cluster_id)[0]\n",
    "    for idx in indices:\n",
    "        print(f\"  ‚Ä¢ {news_articles[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è\n",
    "\n",
    "**–ó–∞–±–µ–ª–µ–∂–µ—Ç–µ**: –ê–ª–≥–æ—Ä–∏—Ç—ä–º—ä—Ç **—Å–∞–º** –æ—Ç–∫—Ä–∏ —á–µ:\n",
    "- –ì—Ä—É–ø–∞ 0: –°–ø–æ—Ä—Ç–Ω–∏ –Ω–æ–≤–∏–Ω–∏\n",
    "- –ì—Ä—É–ø–∞ 1: –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–Ω–∏ –Ω–æ–≤–∏–Ω–∏\n",
    "- –ì—Ä—É–ø–∞ 2: –ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–æ–≤–∏–Ω–∏\n",
    "\n",
    "–ù–∏–∫–æ–π –Ω–µ –º—É –∫–∞–∑–∞ –∫–æ–∏ —Å–∞ —Ç–µ–º–∏—Ç–µ - —Ç–æ–π –≥–∏ –æ—Ç–∫—Ä–∏ –æ—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ—Ç–æ –≤ –¥—É–º–∏—Ç–µ!\n",
    "\n",
    "**–†–µ–∞–ª–Ω–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**:\n",
    "- –û—Ä–≥–∞–Ω–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "- –ì—Ä—É–ø–∏—Ä–∞–Ω–µ –Ω–∞ –∫–ª–∏–µ–Ω—Ç—Å–∫–∏ –æ–ø–ª–∞–∫–≤–∞–Ω–∏—è –ø–æ —Ç–µ–º–∏\n",
    "- –û—Ç–∫—Ä–∏–≤–∞–Ω–µ –Ω–∞ —Ç–µ–º–∏ –≤ —Å–æ—Ü–∏–∞–ª–Ω–∏ –º–µ–¥–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3 –û–±—É—á–µ–Ω–∏–µ —á—Ä–µ–∑ –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ (Reinforcement Learning)\n",
    "\n",
    "–ê–≥–µ–Ω—Ç—ä—Ç —É—á–∏ —á—Ä–µ–∑ **–æ–ø–∏—Ç –∏ –≥—Ä–µ—à–∫–∞**, –ø–æ–ª—É—á–∞–≤–∞–π–∫–∏ –Ω–∞–≥—Ä–∞–¥–∏ –∏–ª–∏ –Ω–∞–∫–∞–∑–∞–Ω–∏—è.\n",
    "\n",
    "### –í—Ä—ä–∑–∫–∞ —Å NLP\n",
    "\n",
    "**RLHF (Reinforcement Learning from Human Feedback)** –µ –∫–ª—é—á–æ–≤–∞ —Ç–µ—Ö–Ω–∏–∫–∞ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å—ä–≤—Ä–µ–º–µ–Ω–Ω–∏ LLM:\n",
    "\n",
    "1. –ú–æ–¥–µ–ª—ä—Ç –≥–µ–Ω–µ—Ä–∏—Ä–∞ –æ—Ç–≥–æ–≤–æ—Ä\n",
    "2. –ß–æ–≤–µ–∫ –æ—Ü–µ–Ω—è–≤–∞ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ (–Ω–∞–≥—Ä–∞–¥–∞)\n",
    "3. –ú–æ–¥–µ–ª—ä—Ç —É—á–∏ –¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞ –ø–æ-–¥–æ–±—Ä–∏ –æ—Ç–≥–æ–≤–æ—Ä–∏\n",
    "\n",
    "**–ü—Ä–∏–º–µ—Ä–∏**:\n",
    "- ChatGPT –∏ Claude —Å–∞ –æ–±—É—á–µ–Ω–∏ —Å RLHF\n",
    "- –î–∏–∞–ª–æ–≥–æ–≤–∏ —Å–∏—Å—Ç–µ–º–∏, –∫–æ–∏—Ç–æ —É—á–∞—Ç –æ—Ç –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—Å–∫–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è\n",
    "- –°–∏—Å—Ç–µ–º–∏ –∑–∞ –º–∞—à–∏–Ω–µ–Ω –ø—Ä–µ–≤–æ–¥ —Å —á–æ–≤–µ—à–∫–∞ –æ–±—Ä–∞—Ç–Ω–∞ –≤—Ä—ä–∑–∫–∞\n",
    "\n",
    "üìå **–©–µ —Ä–∞–∑–≥–ª–µ–¥–∞–º–µ RLHF –ø–æ–¥—Ä–æ–±–Ω–æ –≤ –õ–µ–∫—Ü–∏—è 8!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. –ì–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è: Overfitting –∏ Underfitting\n",
    "\n",
    "### –ö–∞–∫–≤–æ –µ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è?\n",
    "\n",
    "**–ì–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è—Ç–∞** –µ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª –¥–∞ —Ä–∞–±–æ—Ç–∏ –¥–æ–±—Ä–µ –Ω–∞ **–Ω–æ–≤–∏, –Ω–µ–≤–∏–∂–¥–∞–Ω–∏ –¥–∞–Ω–Ω–∏**.\n",
    "\n",
    "### –î–≤–µ –æ—Å–Ω–æ–≤–Ω–∏ –ø—Ä–æ–±–ª–µ–º–∏\n",
    "\n",
    "#### üî¥ Overfitting (–ü—Ä–µ–ø—ä–ª–≤–∞–Ω–µ)\n",
    "–ú–æ–¥–µ–ª—ä—Ç **–∑–∞–ø–æ–º–Ω—è** —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏, –Ω–æ –Ω–µ –º–æ–∂–µ –¥–∞ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∏—Ä–∞.\n",
    "\n",
    "**–í —Ç–µ–∫—Å—Ç–æ–≤–∏ –º–æ–¥–µ–ª–∏**:\n",
    "- –ó–∞–ø–æ–º–Ω—è —Ç–æ—á–Ω–∏ –∏–∑—Ä–µ—á–µ–Ω–∏—è –æ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—è –Ω–∞–±–æ—Ä\n",
    "- –ù–µ —Ä–∞–±–æ—Ç–∏ –¥–æ–±—Ä–µ —Å –Ω–æ–≤–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏\n",
    "- –ù–µ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞ –Ω–µ–≤–∏–∂–¥–∞–Ω–∏ –¥—É–º–∏\n",
    "\n",
    "#### üîµ Underfitting (–ù–µ–¥–æ–ø—ä–ª–≤–∞–Ω–µ)\n",
    "–ú–æ–¥–µ–ª—ä—Ç –µ **—Ç–≤—ä—Ä–¥–µ –ø—Ä–æ—Å—Ç** –∏ –Ω–µ –º–æ–∂–µ –¥–∞ —É–ª–æ–≤–∏ –º–æ–¥–µ–ª–∏ –≤ –¥–∞–Ω–Ω–∏—Ç–µ.\n",
    "\n",
    "**–í —Ç–µ–∫—Å—Ç–æ–≤–∏ –º–æ–¥–µ–ª–∏**:\n",
    "- Bag-of-words, –∫–æ–π—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞ —Ä–µ–¥–∞ –Ω–∞ –¥—É–º–∏—Ç–µ\n",
    "- –ü—Ä–µ–∫–∞–ª–µ–Ω–æ –ø—Ä–æ—Å—Ç–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n",
    "- –ò–≥–Ω–æ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "\n",
    "### –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å —Ç–µ–∫—Å—Ç–æ–≤–∏ –¥–∞–Ω–Ω–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–∞–ª—ä–∫ dataset –∑–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ overfitting\n",
    "small_texts = [\n",
    "    \"–°—Ç—Ä–∞—Ö–æ—Ç–µ–Ω —Ñ–∏–ª–º\",\n",
    "    \"–ú–Ω–æ–≥–æ –¥–æ–±—ä—Ä —Ñ–∏–ª–º\",\n",
    "    \"–õ–æ—à —Ñ–∏–ª–º\",\n",
    "    \"–£–∂–∞—Å–µ–Ω —Ñ–∏–ª–º\"\n",
    "]\n",
    "small_labels = [1, 1, 0, 0]  # 1=–ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ, 0=–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ\n",
    "\n",
    "# –©–µ —Ç—Ä–µ–Ω–∏—Ä–∞–º–µ –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–ª–∏—á–Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç\n",
    "print(\"üî¨ –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: –í–ª–∏—è–Ω–∏–µ –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∞\\n\")\n",
    "\n",
    "# –ú–æ–¥–µ–ª 1: –ü—Ä–æ—Å—Ç (—Å–∞–º–æ 5 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)\n",
    "vec_simple = TfidfVectorizer(max_features=5)\n",
    "X_simple = vec_simple.fit_transform(small_texts)\n",
    "model_simple = LogisticRegression(random_state=42, C=0.1)\n",
    "model_simple.fit(X_simple, small_labels)\n",
    "train_acc_simple = model_simple.score(X_simple, small_labels)\n",
    "\n",
    "print(f\"üìä –ü—Ä–æ—Å—Ç –º–æ–¥–µ–ª (5 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏):\")\n",
    "print(f\"   –¢–æ—á–Ω–æ—Å—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏: {train_acc_simple:.1%}\")\n",
    "print(f\"   –†–µ—á–Ω–∏–∫: {vec_simple.get_feature_names_out()}\")\n",
    "\n",
    "# –ú–æ–¥–µ–ª 2: –°–ª–æ–∂–µ–Ω (–≤—Å–∏—á–∫–∏ –¥—É–º–∏ + n-–≥—Ä–∞–º–∏)\n",
    "vec_complex = TfidfVectorizer(ngram_range=(1, 3), max_features=100)\n",
    "X_complex = vec_complex.fit_transform(small_texts)\n",
    "model_complex = LogisticRegression(random_state=42, C=100)\n",
    "model_complex.fit(X_complex, small_labels)\n",
    "train_acc_complex = model_complex.score(X_complex, small_labels)\n",
    "\n",
    "print(f\"\\nüìä –°–ª–æ–∂–µ–Ω –º–æ–¥–µ–ª ({X_complex.shape[1]} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏):\")\n",
    "print(f\"   –¢–æ—á–Ω–æ—Å—Ç –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏: {train_acc_complex:.1%}\")\n",
    "print(f\"   –ò–∑–ø–æ–ª–∑–≤–∞ 1-–≥—Ä–∞–º–∏, 2-–≥—Ä–∞–º–∏ –∏ 3-–≥—Ä–∞–º–∏\")\n",
    "\n",
    "# –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∏ —Ñ—Ä–∞–∑–∏\n",
    "test_phrases = [\n",
    "    \"–ü—Ä–µ–∫—Ä–∞—Å–µ–Ω —Ñ–∏–ª–º\",  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ, –Ω–æ –Ω–æ–≤–∞ –¥—É–º–∞\n",
    "    \"–û—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª–µ–Ω —Ñ–∏–ª–º\",  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ, –Ω–æ –Ω–æ–≤–∞ –¥—É–º–∞\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß™ –¢–µ—Å—Ç–≤–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∏ —Ñ—Ä–∞–∑–∏ (–¥—É–º–∏, –∫–æ–∏—Ç–æ –Ω–µ —Å–∞ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—è –Ω–∞–±–æ—Ä):\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for phrase in test_phrases:\n",
    "    # –ü—Ä–æ—Å—Ç –º–æ–¥–µ–ª\n",
    "    phrase_simple = vec_simple.transform([phrase])\n",
    "    pred_simple = model_simple.predict(phrase_simple)[0]\n",
    "    \n",
    "    # –°–ª–æ–∂–µ–Ω –º–æ–¥–µ–ª\n",
    "    phrase_complex = vec_complex.transform([phrase])\n",
    "    pred_complex = model_complex.predict(phrase_complex)[0]\n",
    "    \n",
    "    print(f\"\\n–§—Ä–∞–∑–∞: '{phrase}'\")\n",
    "    print(f\"  –ü—Ä–æ—Å—Ç –º–æ–¥–µ–ª: {'üòä –ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ' if pred_simple == 1 else 'üòû –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ'}\")\n",
    "    print(f\"  –°–ª–æ–∂–µ–Ω –º–æ–¥–µ–ª: {'üòä –ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ' if pred_complex == 1 else 'üòû –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ'}\")\n",
    "\n",
    "print(\"\\nüí° –ó–∞–±–µ–ª–µ–∂–∫–∞: –ù–∞ –º–∞–ª–∫–∏ –¥–∞–Ω–Ω–∏, —Å–ª–æ–∂–Ω–∏—è—Ç –º–æ–¥–µ–ª –º–æ–∂–µ –¥–∞ overfit–Ω–µ,\")\n",
    "print(\"   –¥–æ–∫–∞—Ç–æ –ø—Ä–æ—Å—Ç–∏—è—Ç –º–æ–¥–µ–ª –º–æ–∂–µ –¥–∞ underfit–Ω–µ.\")\n",
    "print(\"   –ë–∞–ª–∞–Ω—Å—ä—Ç –µ –∫–ª—é—á–æ–≤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–∞–∫ –¥–∞ –∏–∑–±–µ–≥–Ω–µ–º overfitting?\n",
    "\n",
    "1. **–ü–æ–≤–µ—á–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏ –¥–∞–Ω–Ω–∏** üìä\n",
    "2. **–†–µ–≥—É–ª–∞—Ä–∏–∑–∞—Ü–∏—è** (L1, L2) ‚öñÔ∏è\n",
    "3. **–ö—Ä—ä—Å—Ç–æ—Å–∞–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è** üîÑ\n",
    "4. **–ü–æ-–ø—Ä–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏** üìâ\n",
    "5. **Early stopping** ‚è∏Ô∏è\n",
    "\n",
    "### –í—Ä—ä–∑–∫–∞ —Å LLM\n",
    "\n",
    "–°—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ LLM (ChatGPT, Claude) —Å–µ –æ–±—É—á–∞–≤–∞—Ç –Ω–∞ **—Ç—Ä–∏–ª–∏–æ–Ω–∏** —Ç–æ–∫–µ–Ω–∏, –∫–æ–µ—Ç–æ –∏–º –ø–æ–∑–≤–æ–ª—è–≤–∞ –¥–∞ –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∏—Ä–∞—Ç –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ –¥–æ–±—Ä–µ!\n",
    "\n",
    "üìå **–©–µ —Ä–∞–∑–≥–ª–µ–¥–∞–º–µ scaling laws –≤ –õ–µ–∫—Ü–∏—è 6-7!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. –ú–µ—Ç—Ä–∏–∫–∏ –∑–∞ –æ—Ü–µ–Ω–∫–∞\n",
    "\n",
    "### –ó–∞ –∫–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ —Ç–µ–∫—Å—Ç\n",
    "\n",
    "#### –¢–æ—á–Ω–æ—Å—Ç (Accuracy)\n",
    "$$\\text{Accuracy} = \\frac{\\text{–ë—Ä–æ–π –ø—Ä–∞–≤–∏–ª–Ω–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è}}{\\text{–û–±—â –±—Ä–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è}}$$\n",
    "\n",
    "#### –ü—Ä–µ—Ü–∏–∑–Ω–æ—Å—Ç (Precision)\n",
    "–û—Ç –≤—Å–∏—á–∫–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏ –∫–∞—Ç–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏, –∫–æ–ª–∫–æ –Ω–∞–∏—Å—Ç–∏–Ω–∞ —Å–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏?\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "#### –ü—ä–ª–Ω–æ—Ç–∞ (Recall)\n",
    "–û—Ç –≤—Å–∏—á–∫–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–Ω–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏, –∫–æ–ª–∫–æ —Å–º–µ –æ—Ç–∫—Ä–∏–ª–∏?\n",
    "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "#### F1-Score\n",
    "–•–∞—Ä–º–æ–Ω–∏—á–Ω–∞ —Å—Ä–µ–¥–Ω–∞ –Ω–∞ Precision –∏ Recall\n",
    "$$F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–∑–ø–æ–ª–∑–≤–∞–º–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ç–∞ –æ—Ç –ø–æ-—Ä–∞–Ω–æ\n",
    "print(\"üìä –î–ï–¢–ê–ô–õ–ù–ò –ú–ï–¢–†–ò–ö–ò –ó–ê –ö–õ–ê–°–ò–§–ò–ö–ê–¶–ò–Ø –ù–ê –ù–ê–°–¢–†–û–ï–ù–ò–Ø\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(\"–î–µ—Ç–∞–π–ª–µ–Ω –¥–æ–∫–ª–∞–¥:\")\n",
    "print(\"=\" * 60)\n",
    "report = classification_report(y_test, y_pred, \n",
    "                               target_names=['–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ', '–ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ'],\n",
    "                               zero_division=0)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ', '–ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ'],\n",
    "            yticklabels=['–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ', '–ü–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ'],\n",
    "            cbar_kws={'label': '–ë—Ä–æ–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è'})\n",
    "plt.ylabel('–ò—Å—Ç–∏–Ω—Å–∫–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç', fontsize=12)\n",
    "plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç', fontsize=12)\n",
    "plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –Ω–∞ –æ–±—ä—Ä–∫–≤–∞–Ω–µ (Confusion Matrix)', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìñ –ö–∞–∫ –¥–∞ —á–µ—Ç–µ–º –º–∞—Ç—Ä–∏—Ü–∞—Ç–∞:\")\n",
    "print(f\"  ‚úì –ì–æ—Ä–µ-–ª—è–≤–æ: –ü—Ä–∞–≤–∏–ª–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–∏ ({cm[0,0]})\")\n",
    "print(f\"  ‚úì –î–æ–ª—É-–¥—è—Å–Ω–æ: –ü—Ä–∞–≤–∏–ª–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏ ({cm[1,1]})\")\n",
    "print(f\"  ‚úó –ì–æ—Ä–µ-–¥—è—Å–Ω–æ: –§–∞–ª—à–∏–≤–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∏ - –≥—Ä–µ—à–∫–∞ —Ç–∏–ø I ({cm[0,1]})\")\n",
    "print(f\"  ‚úó –î–æ–ª—É-–ª—è–≤–æ: –§–∞–ª—à–∏–≤–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–∏ - –≥—Ä–µ—à–∫–∞ —Ç–∏–ø II ({cm[1,0]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–ø–µ—Ü–∏–∞–ª–Ω–∏ NLP –º–µ—Ç—Ä–∏–∫–∏\n",
    "\n",
    "#### Perplexity (–∑–∞ –µ–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏)\n",
    "–ò–∑–º–µ—Ä–≤–∞ –∫–æ–ª–∫–æ \"–æ–±—ä—Ä–∫–∞–Ω\" –µ –º–æ–¥–µ–ª—ä—Ç –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Å–ª–µ–¥–≤–∞—â–∞—Ç–∞ –¥—É–º–∞.\n",
    "\n",
    "$$\\text{Perplexity} = 2^{-\\frac{1}{N}\\sum_{i=1}^{N}\\log_2 P(w_i|w_1,...,w_{i-1})}$$\n",
    "\n",
    "–ü–æ-–Ω–∏—Å–∫–∞ perplexity = –ø–æ-–¥–æ–±—ä—Ä –º–æ–¥–µ–ª\n",
    "\n",
    "#### BLEU Score (–∑–∞ –º–∞—à–∏–Ω–µ–Ω –ø—Ä–µ–≤–æ–¥)\n",
    "–°—Ä–∞–≤–Ω—è–≤–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞–Ω –ø—Ä–µ–≤–æ–¥ —Å —Ä–µ—Ñ–µ—Ä–µ–Ω—Ç–Ω–∏ –ø—Ä–µ–≤–æ–¥–∏, –±–∞–∑–∏—Ä–∞–π–∫–∏ —Å–µ –Ω–∞ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞ n-–≥—Ä–∞–º–∏.\n",
    "\n",
    "üìå **–©–µ –≤–∏–¥–∏–º —Ç–µ–∑–∏ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–ª–µ–¥–≤–∞—â–∏—Ç–µ –ª–µ–∫—Ü–∏–∏!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. NLP-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∏ –ø—Ä–µ–¥–∏–∑–≤–∏–∫–∞—Ç–µ–ª—Å—Ç–≤–∞\n",
    "\n",
    "### 1. –ü—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç –∫–∞—Ç–æ —á–∏—Å–ª–∞\n",
    "- Bag of Words ‚úì (–≤–∏–¥—è—Ö–º–µ)\n",
    "- TF-IDF ‚úì (–≤–∏–¥—è—Ö–º–µ)\n",
    "- Word2Vec ‚Üí **–õ–µ–∫—Ü–∏—è 2**\n",
    "- Embeddings ‚Üí **–õ–µ–∫—Ü–∏—è 2**\n",
    "- Contextualized embeddings (BERT) ‚Üí **–õ–µ–∫—Ü–∏—è 5**\n",
    "\n",
    "### 2. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "–ö–∞–∫ —Ä–∞–∑–¥–µ–ª—è–º–µ —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏?\n",
    "- –î—É–º–∏\n",
    "- –ü–æ–¥–¥—É–º–∏ (BPE, WordPiece)\n",
    "- –°–∏–º–≤–æ–ª–∏\n",
    "\n",
    "üìå **–¶—è–ª–∞ –ª–µ–∫—Ü–∏—è –∑–∞ —Ç–æ–≤–∞ ‚Üí –õ–µ–∫—Ü–∏—è 3**\n",
    "\n",
    "### 3. –ü—Ä–æ–º–µ–Ω–ª–∏–≤–∞ –¥—ä–ª–∂–∏–Ω–∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ—Å—Ç–∏—Ç–µ\n",
    "–ò–∑—Ä–µ—á–µ–Ω–∏—è—Ç–∞ –∏–º–∞—Ç —Ä–∞–∑–ª–∏—á–Ω–∞ –¥—ä–ª–∂–∏–Ω–∞. –ö–∞–∫ –≥–∏ –æ–±—Ä–∞–±–æ—Ç–≤–∞–º–µ?\n",
    "- Padding (–∑–∞–ø—ä–ª–≤–∞–Ω–µ)\n",
    "- Truncation (–æ—Ç—Ä—è–∑–≤–∞–Ω–µ)\n",
    "- –†–µ–∫—É—Ä–µ–Ω—Ç–Ω–∏ –º—Ä–µ–∂–∏ (RNN)\n",
    "- Attention –º–µ—Ö–∞–Ω–∏–∑–º–∏\n",
    "\n",
    "üìå **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∏ ‚Üí –õ–µ–∫—Ü–∏—è 5**\n",
    "\n",
    "### 4. –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "\"–ë–∞–Ω–∫–∞—Ç–∞ –µ –∑–∞—Ç–≤–æ—Ä–µ–Ω–∞\" - —Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞ –∏–Ω—Å—Ç–∏—Ç—É—Ü–∏—è –∏–ª–∏ —Ä–µ—á–µ–Ω –±—Ä—è–≥?\n",
    "\n",
    "–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–∏ –º–µ—Ç–æ–¥–∏ (Bag of Words) –∏–≥–Ω–æ—Ä–∏—Ä–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç.  \n",
    "–°—ä–≤—Ä–µ–º–µ–Ω–Ω–∏ –º–æ–¥–µ–ª–∏ (BERT, GPT) –∏–∑–ø–æ–ª–∑–≤–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç!\n",
    "\n",
    "### 5. –ú–∞—â–∞–± –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ\n",
    "–°—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ LLM —Å–µ –æ–±—É—á–∞–≤–∞—Ç –Ω–∞:\n",
    "- –¢—Ä–∏–ª–∏–æ–Ω–∏ —Ç–æ–∫–µ–Ω–∏\n",
    "- –°—Ç–æ—Ç–∏—Ü–∏ GB —Ç–µ–∫—Å—Ç\n",
    "- –•–∏–ª—è–¥–∏ GPU —á–∞—Å–æ–≤–µ\n",
    "\n",
    "üìå **Scaling laws ‚Üí –õ–µ–∫—Ü–∏—è 6-7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ NLP workflow\n",
    "\n",
    "### –°—Ç—ä–ø–∫–∏ –ø—Ä–∏ —Ä–µ—à–∞–≤–∞–Ω–µ –Ω–∞ NLP –∑–∞–¥–∞—á–∞\n",
    "\n",
    "```\n",
    "1. –î–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –∑–∞–¥–∞—á–∞—Ç–∞\n",
    "   ‚Üì\n",
    "2. –°—ä–±–∏—Ä–∞–Ω–µ –∏ –ø—Ä–æ—É—á–≤–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏ –¥–∞–Ω–Ω–∏\n",
    "   ‚Üì\n",
    "3. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (lowercase, –ø—Ä–µ–º–∞—Ö–≤–∞–Ω–µ –Ω–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è, ...)\n",
    "   ‚Üì\n",
    "4. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "   ‚Üì\n",
    "5. –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ / Embeddings\n",
    "   ‚Üì\n",
    "6. –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ train/val/test\n",
    "   ‚Üì\n",
    "7. –ò–∑–±–æ—Ä –∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª\n",
    "   ‚Üì\n",
    "8. –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—è –Ω–∞–±–æ—Ä\n",
    "   ‚Üì\n",
    "9. –ê–Ω–∞–ª–∏–∑ –Ω–∞ –≥—Ä–µ—à–∫–∏\n",
    "   ‚Üì\n",
    "10. –ò—Ç–µ—Ä–∞—Ü–∏—è –∏ –ø–æ–¥–æ–±—Ä–µ–Ω–∏–µ\n",
    "```\n",
    "\n",
    "### –ß–µ—Å—Ç–æ —Å—Ä–µ—â–∞–Ω–∏ –∫–∞–ø–∞–Ω–∏ –≤ NLP\n",
    "\n",
    "‚ö†Ô∏è **Data leakage**: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç —Ç–µ—Å—Ç–æ–≤–∏—è –Ω–∞–±–æ—Ä \"–∏–∑—Ç–∏—á–∞\" –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–Ω–∏—è  \n",
    "‚ö†Ô∏è **Test set contamination**: –û—Å–æ–±–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º –∑–∞ LLM (–≤–∏–∂–¥–∞–ª–∏ –ª–∏ —Å–∞ –¥–∞–Ω–Ω–∏—Ç–µ?)  \n",
    "‚ö†Ô∏è **Vocabulary mismatch**: –ú–æ–¥–µ–ª –≤–∏–∂–¥–∞ –Ω–æ–≤–∏ –¥—É–º–∏ –Ω–∞ —Ç–µ—Å—Ç –≤—Ä–µ–º–µ  \n",
    "‚ö†Ô∏è **Class imbalance**: –ù–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –∫–ª–∞—Å–æ–≤–µ—Ç–µ  \n",
    "‚ö†Ô∏è **Domain shift**: –¢—Ä–µ–Ω–∏—Ä–∞–Ω–∏ –Ω–∞ –Ω–æ–≤–∏–Ω–∏, —Ç–µ—Å—Ç–≤–∞–Ω–∏ –Ω–∞ —Ç—É–∏—Ç–æ–≤–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ vocabulary mismatch –ø—Ä–æ–±–ª–µ–º\n",
    "print(\"‚ö†Ô∏è  –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø: Vocabulary Mismatch Problem\\n\")\n",
    "\n",
    "train_texts_demo = [\"–¥–æ–±—ä—Ä —Ñ–∏–ª–º\", \"–ª–æ—à —Ñ–∏–ª–º\", \"—Å—Ç—Ä–∞—Ö–æ—Ç–µ–Ω —Ñ–∏–ª–º\"]\n",
    "train_labels_demo = [1, 0, 1]\n",
    "\n",
    "# –û–±—É—á–∞–≤–∞–º–µ –º–æ–¥–µ–ª\n",
    "vec_demo = CountVectorizer()\n",
    "X_train_demo = vec_demo.fit_transform(train_texts_demo)\n",
    "model_demo = LogisticRegression()\n",
    "model_demo.fit(X_train_demo, train_labels_demo)\n",
    "\n",
    "print(\"–¢—Ä–µ–Ω–∏—Ä–æ–≤—ä—á–µ–Ω —Ä–µ—á–Ω–∏–∫:\")\n",
    "print(vec_demo.get_feature_names_out())\n",
    "\n",
    "# –¢–µ—Å—Ç–≤–∞–º–µ —Å —Ç–µ–∫—Å—Ç, —Å—ä–¥—ä—Ä–∂–∞—â –Ω–æ–≤–∏ –¥—É–º–∏\n",
    "test_text = [\"–ø—Ä–µ–≤—ä–∑—Ö–æ–¥–µ–Ω —Ñ–∏–ª–º\"]\n",
    "print(f\"\\n–¢–µ—Å—Ç–æ–≤ —Ç–µ–∫—Å—Ç: '{test_text[0]}'\")\n",
    "print(\"–ü—Ä–æ–±–ª–µ–º: –î—É–º–∞—Ç–∞ '–ø—Ä–µ–≤—ä–∑—Ö–æ–¥–µ–Ω' –Ω–µ –µ –≤—ä–≤ —Ä–µ—á–Ω–∏–∫–∞!\")\n",
    "\n",
    "X_test_demo = vec_demo.transform(test_text)\n",
    "print(f\"\\n–ü—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–∏—è —Ç–µ–∫—Å—Ç: {X_test_demo.toarray()}\")\n",
    "print(\"‚Üí –í—Å–∏—á–∫–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å–∞ 0! –ú–æ–¥–µ–ª—ä—Ç '–Ω–µ –≤–∏–∂–¥–∞' –Ω–æ–≤–∞—Ç–∞ –¥—É–º–∞.\")\n",
    "\n",
    "print(\"\\nüí° –†–µ—à–µ–Ω–∏—è:\")\n",
    "print(\"  1. –ò–∑–ø–æ–ª–∑–≤–∞–π embeddings –≤–º–µ—Å—Ç–æ bag-of-words (–õ–µ–∫—Ü–∏—è 2)\")\n",
    "print(\"  2. –û–±—É—á–∞–≤–∞–π –Ω–∞ –ø–æ-–≥–æ–ª–µ–º–∏ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–∏ datasets\")\n",
    "print(\"  3. –ò–∑–ø–æ–ª–∑–≤–∞–π –ø–æ–¥–¥—É–º–µ–Ω —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è (BPE) (–õ–µ–∫—Ü–∏—è 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. –û–±–æ–±—â–µ–Ω–∏–µ –∏ –º–æ—Å—Ç –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∞—Ç–∞ –ª–µ–∫—Ü–∏—è\n",
    "\n",
    "### üéì –ö–ª—é—á–æ–≤–∏ –∏–∑–≤–æ–¥–∏\n",
    "\n",
    "#### –î–Ω–µ—Å –Ω–∞—É—á–∏—Ö–º–µ:\n",
    "\n",
    "1. **ML –æ—Å–Ω–æ–≤–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏ –∑–∞ NLP**\n",
    "   - –§–æ—Ä–º—É–ª–∏—Ä–∞–Ω–µ –Ω–∞ –∑–∞–¥–∞—á–∏ —Å —Ç–µ–∫—Å—Ç–æ–≤–∏ –¥–∞–Ω–Ω–∏\n",
    "   - –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: Bag of Words, TF-IDF, n-–≥—Ä–∞–º–∏\n",
    "\n",
    "2. **–¢—Ä–∏ –ø–∞—Ä–∞–¥–∏–≥–º–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ**\n",
    "   - **Supervised**: –ê–Ω–∞–ª–∏–∑ –Ω–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è, –∫–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ —Ç–µ–∫—Å—Ç\n",
    "   - **Unsupervised**: –ì—Ä—É–ø–∏—Ä–∞–Ω–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∏, –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ –Ω–∞ —Ç–µ–º–∏\n",
    "   - **Reinforcement**: RLHF –∑–∞ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ LLM (—â–µ –≤–∏–¥–∏–º –≤ –õ–µ–∫—Ü–∏—è 8)\n",
    "\n",
    "3. **–í–∞–∂–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏**\n",
    "   - Train/Test split –∑–∞ –≤–∞–ª–∏–¥–Ω–∞ –æ—Ü–µ–Ω–∫–∞\n",
    "   - Overfitting –∏ underfitting –≤ —Ç–µ–∫—Å—Ç–æ–≤–∏ –º–æ–¥–µ–ª–∏\n",
    "   - –ú–µ—Ç—Ä–∏–∫–∏: Accuracy, Precision, Recall, F1\n",
    "\n",
    "4. **NLP –ø—Ä–µ–¥–∏–∑–≤–∏–∫–∞—Ç–µ–ª—Å—Ç–≤–∞**\n",
    "   - –ü—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç –∫–∞—Ç–æ —á–∏—Å–ª–∞\n",
    "   - –ü—Ä–æ–º–µ–Ω–ª–∏–≤–∞ –¥—ä–ª–∂–∏–Ω–∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ—Å—Ç–∏\n",
    "   - –í–∞–∂–Ω–æ—Å—Ç—Ç–∞ –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "   - Vocabulary mismatch\n",
    "\n",
    "### üîú –°–ª–µ–¥–≤–∞—â–∞ –ª–µ–∫—Ü–∏—è: –ï–∑–∏–∫–æ–≤–∏ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ –Ω–∞ –¥—É–º–∏\n",
    "\n",
    "**–©–µ –æ—Ç–≥–æ–≤–æ—Ä–∏–º –Ω–∞ –∫—Ä–∏—Ç–∏—á–Ω–∏ –≤—ä–ø—Ä–æ—Å–∏:**\n",
    "\n",
    "‚ùì –ö–∞–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤—è–º–µ –¥—É–º–∏—Ç–µ –ø–æ-–¥–æ–±—Ä–µ –æ—Ç Bag of Words?  \n",
    "‚ùì –ö–∞–∫ —É–ª–∞–≤—è–º–µ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∞ –ø—Ä–∏–ª–∏–∫–∞? (\"–∫—Ä–∞–ª\" ‚âà \"–∫—Ä–∞–ª–∏—Ü–∞\")  \n",
    "‚ùì –ö–∞–∫–≤–æ –µ Word2Vec –∏ –∫–∞–∫ —Ä–∞–±–æ—Ç–∏?  \n",
    "‚ùì –ö–∞–∫–≤–æ –µ –µ–∑–∏–∫–æ–≤ –º–æ–¥–µ–ª?  \n",
    "‚ùì –ö–∞–∫ –∏–∑–º–µ—Ä–≤–∞–º–µ –∫–∞—á–µ—Å—Ç–≤–æ—Ç–æ –º—É (Perplexity)?  \n",
    "\n",
    "### üìö –ü—Ä–µ–ø–æ—Ä—ä—á–∏—Ç–µ–ª–Ω–æ —á–µ—Ç–µ–Ω–µ\n",
    "\n",
    "1. **\"A Few Useful Things to Know About Machine Learning\"** - Pedro Domingos (2012)\n",
    "2. **\"Speech and Language Processing\"** (3rd ed.) - Jurafsky & Martin\n",
    "   - Chapter 4: Naive Bayes and Sentiment Classification\n",
    "   - Chapter 6: Vector Semantics and Embeddings (–ø—Ä–µ–≥–ª–µ–¥ –∑–∞ —Å–ª–µ–¥–≤–∞—â–∞—Ç–∞ –ª–µ–∫—Ü–∏—è)\n",
    "3. **Stanford CS224N Lecture 1**: Introduction to NLP and Deep Learning\n",
    "\n",
    "### üèãÔ∏è –£–ø—Ä–∞–∂–Ω–µ–Ω–∏—è –∑–∞ –≤–∫—ä—â–∏\n",
    "\n",
    "1. –ò–∑—Ç–µ–≥–ª–µ—Ç–µ IMDB dataset –∏ –æ–±—É—á–µ—Ç–µ sentiment classifier\n",
    "2. –°—Ä–∞–≤–Ω–µ—Ç–µ Bag-of-Words vs TF-IDF vs n-–≥—Ä–∞–º–∏\n",
    "3. –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–π—Ç–µ –≥—Ä–µ—à–∫–∏—Ç–µ –Ω–∞ –º–æ–¥–µ–ª–∞ - –∫–æ–∏ —Ç–∏–ø–æ–≤–µ –∏–∑—Ä–µ—á–µ–Ω–∏—è —Å–∞ —Ç—Ä—É–¥–Ω–∏?\n",
    "4. –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–∞–π—Ç–µ —Å —Ä–∞–∑–ª–∏—á–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –Ω–∞ max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## –ö—Ä–∞–π –Ω–∞ –õ–µ–∫—Ü–∏—è 1\n",
    "\n",
    "### –ë–ª–∞–≥–æ–¥–∞—Ä—è –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ—Ç–æ! üéâ\n",
    "\n",
    "**–í—ä–ø—Ä–æ—Å–∏? ü§î**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
