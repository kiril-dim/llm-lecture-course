# Изпит: Вариант A

**Инструкции:** Решете всички 8 задачи. Показвайте изчисленията си.

---

## Задача 1: Метрики за класификация (12 точки)

Модел за откриване на спам имейли е тестван на 500 съобщения с резултати:
- 320 легитимни имейла правилно класифицирани като легитимни
- 30 легитимни имейла грешно класифицирани като спам
- 120 спам имейла правилно класифицирани като спам
- 30 спам имейла грешно класифицирани като легитимни

**Задача:**
a) Попълнете confusion matrix (TP, TN, FP, FN за класа "спам")
b) Изчислете Precision за класа "спам"
c) Изчислете Recall за класа "спам"
d) Изчислете F1-score
e) Защо в този случай Recall е по-важен от Precision?

**Формули:**
- $Precision = \frac{TP}{TP + FP}$
- $Recall = \frac{TP}{TP + FN}$
- $F_1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$

---

## Задача 2: Tokenization и BPE (12 точки)

Дадени са BPE merge правила (в ред на научаване):
1. (a, b) → ab
2. (ab, c) → abc
3. (d, e) → de
4. (abc, de) → abcde

**Задача:**
a) Токенизирайте думата `"abcdef"` стъпка по стъпка, започвайки от символи
b) Колко токена има финалният резултат?
c) Ако добавим думата `"xyabcz"` към корпуса (никога не е виждана), как ще се токенизира?
d) Защо BPE е подходящ за редки и нови думи?

---

## Задача 3: Self-Attention изчисление (15 точки)

Дадени са Query и Key вектори за 3 токена:
```
Q = [[2, 0],    # токен 1
     [0, 2],    # токен 2
     [1, 1]]    # токен 3

K = [[1, 0],    # токен 1
     [0, 1],    # токен 2
     [1, 1]]    # токен 3
```

**Задача:**
a) Изчислете attention scores матрицата $QK^T$
b) Ако $d_k = 2$, какъв е scaling factor $\sqrt{d_k}$?
c) Приложете scaling: $\frac{QK^T}{\sqrt{d_k}}$
d) За кой токен (1, 2 или 3) token 3 има най-силен attention?
e) Защо scaling е необходим преди softmax?

---

## Задача 4: Transformer параметри (12 точки)

Модел има следните характеристики:
- $d_{model} = 1024$
- $n_{heads} = 16$
- $n_{layers} = 24$
- FFN expansion factor: 4x

**Задача:**
a) Каква е размерността на всеки attention head ($d_k$)?
b) Колко параметъра има един attention слой (Q, K, V, O проекции, без bias)?
c) Колко параметъра има един FFN слой (две линейни трансформации, без bias)?
d) Колко параметъра има цялият модел (само attention + FFN, без embeddings)?

---

## Задача 5: Scaling Laws и Compute (12 точки)

Chinchilla препоръчва ~20 токена на параметър за compute-optimal training.

**Данни:**
- Модел A: 13B параметъра, трениран на 500B токена
- Модел B: 30B параметъра, трениран на 200B токена

Формула за compute: $C \approx 6ND$

**Задача:**
a) Изчислете compute (в FLOPs) за всеки модел
b) Кой модел използва повече compute?
c) Кой модел е по-близо до Chinchilla optimal?
d) За compute budget от Модел A, какъв би бил оптималният размер на модела?

---

## Задача 6: RLHF и Alignment (12 точки)

RLHF objective е:
$$\text{maximize } \mathbb{E}[r(x, y)] - \beta \cdot D_{KL}(\pi_\theta || \pi_{ref})$$

Имате следните данни от training:

| Epoch | Reward | KL Divergence | Human Eval |
|-------|--------|---------------|------------|
| 0     | 0.3    | 0             | 55%        |
| 5     | 0.8    | 1.5           | 68%        |
| 10    | 1.4    | 4.2           | 74%        |
| 15    | 2.1    | 9.8           | 71%        |
| 20    | 2.8    | 18.5          | 63%        |

**Въпроси:**
a) В коя епоха е оптимално да спрем training-а?
b) Какво се случва след epoch 10?
c) Какво е "reward hacking" и как го виждаме в данните?
d) Как KL penalty помага срещу този проблем?

---

## Задача 7: RAG Pipeline (13 точки)

Имате RAG система с:
- Embedding model: 768 dimensions
- Vector database с 100,000 документа
- Top-k retrieval с k=5
- LLM с 4096 token context window

Резултати от retrieval за един query:

| Rank | Similarity | Токени | Релевантен? |
|------|------------|--------|-------------|
| 1    | 0.89       | 450    | Да          |
| 2    | 0.82       | 380    | Да          |
| 3    | 0.75       | 520    | Не          |
| 4    | 0.68       | 410    | Да          |
| 5    | 0.61       | 490    | Не          |

System prompt: 150 токена, User query: 80 токена, Очакван output: 400 токена

**Задача:**
a) Изчислете Precision@5
b) Колко токена заемат retrieved документите?
c) Колко токена остават свободни в context window?
d) Защо включването на нерелевантни документи (rank 3, 5) може да навреди на отговора?
e) Какво е HyDE и как може да подобри retrieval качеството?

---

## Задача 8: Agents и Error Accumulation (12 точки)

Coding agent трябва да изпълни задача, разбита на 6 стъпки:
1. Прочитане на спецификация (95% успех)
2. Планиране на архитектура (85% успех)
3. Писане на основен код (80% успех)
4. Писане на unit tests (75% успех)
5. Debug и fix (70% успех)
6. Documentation (90% успех)

**Задача:**
a) Каква е вероятността цялата задача да завърши успешно?
b) Ако всяка стъпка имаше 95% успех, каква би била общата вероятност?
c) Защо multi-step agents са ненадеждни за production системи?
d) Предложете две стратегии за подобряване на reliability

**Формула:** $P_{total} = P_1 \times P_2 \times ... \times P_n$

---

# Скала за оценяване

| Точки | Оценка |
|-------|--------|
| 90-100 | Отличен (6) |
| 75-89 | Много добър (5) |
| 60-74 | Добър (4) |
| 50-59 | Среден (3) |
| < 50 | Слаб (2) |
