# Лекция 1: Упражнения

**Инструкции:** Тези упражнения покриват основните концепции от лекцията. За всяко упражнение изчислете или изведете отговора на ръка. Решенията са дадени накрая.

---

## Упражнение 1: Bag-of-Words вектори

Дадени са две изречения:
- A: "филмът е добър"
- B: "филмът е лош и скучен"

**Задача:** Напишете Bag-of-Words вектора за всяко изречение. Използвайте азбучен ред на думите в речника.

---

## Упражнение 2: TF-IDF изчисление

Имате колекция от 3 документа. Думата "модел" се среща:
- В документ 1: 4 пъти (документ с 100 думи)
- В документ 2: 0 пъти
- В документ 3: 2 пъти (документ с 50 думи)

**Задача:** Изчислете TF-IDF тежестта на "модел" за документ 1.

Формули:
- $TF = \frac{\text{брой на думата в документа}}{\text{общ брой думи в документа}}$
- $IDF = \log\frac{\text{общ брой документи}}{\text{брой документи, съдържащи думата}}$
- $TF\text{-}IDF = TF \times IDF$

---

## Упражнение 3: Confusion Matrix

Spam класификатор е тестван на 200 имейла с резултати:
- 150 не-spam имейла правилно класифицирани като не-spam
- 10 не-spam имейла грешно класифицирани като spam
- 30 spam имейла правилно класифицирани като spam
- 10 spam имейла грешно класифицирани като не-spam

**Задача:**
a) Попълнете confusion matrix-а (TP, TN, FP, FN)
b) Изчислете Precision за класа "spam"
c) Изчислете Recall за класа "spam"

---

## Упражнение 4: F1-score

Модел има:
- Precision = 0.8
- Recall = 0.6

**Задача:** Изчислете F1-score.

Формула: $F_1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$

---

## Упражнение 5: Accuracy при дисбаланс

Dataset съдържа 1000 примера:
- 950 от клас A
- 50 от клас B

Модел 1 винаги предсказва клас A.
Модел 2 има: 900 TP за A, 40 TP за B, 50 FP за A (предсказва A, но е B), 10 FN за A (предсказва B, но е A).

**Задача:**
a) Изчислете accuracy на Модел 1
b) Изчислете accuracy на Модел 2
c) Кой модел е по-полезен и защо?

---

## Упражнение 6: Train/Validation/Test Split

Имате dataset с 10,000 примера. Искате:
- 70% за training
- 15% за validation
- 15% за test

**Задача:** Колко примера ще има във всеки набор?

---

## Упражнение 7: Cross-Entropy Loss

За бинарна класификация с един пример:
- Истински етикет: $y = 1$ (positive)
- Предсказана вероятност: $\hat{y} = 0.8$

**Задача:** Изчислете binary cross-entropy loss за този пример.

Формула: $L = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})]$

Използвайте $\log$ = натурален логаритъм, $\ln(0.8) \approx -0.223$

---

## Упражнение 8: Bias-Variance

Три модела са оценени на тестови данни:

| Модел | Train Error | Test Error |
|-------|-------------|------------|
| A | 2% | 3% |
| B | 1% | 15% |
| C | 20% | 22% |

**Задача:** За всеки модел определете дали има проблем с:
- High bias (underfitting)
- High variance (overfitting)
- Добър баланс

---

## Упражнение 9: Размерност на BoW

Речникът съдържа 5000 уникални думи. Имате 1000 документа.

**Задача:**
a) Каква е размерността на един BoW вектор?
b) Каква е размерността на целия BoW матрица (документи × признаци)?
c) Ако средно документ съдържа 50 уникални думи, какъв процент от вектора е нули?

---

## Упражнение 10: Stratified Split

Dataset за sentiment analysis съдържа:
- 800 positive примера
- 200 negative примера

При stratified 80/20 split за train/test:

**Задача:** Колко positive и negative примера ще има в:
a) Training set
b) Test set

---

# Решения

## Решение 1
Речник (азбучен ред): {добър, е, и, лош, скучен, филмът}

- A: [1, 1, 0, 0, 0, 1]
- B: [0, 1, 1, 1, 1, 1]

## Решение 2
- $TF = 4/100 = 0.04$
- $IDF = \log(3/2) = \log(1.5) \approx 0.405$
- $TF\text{-}IDF = 0.04 \times 0.405 \approx 0.0162$

## Решение 3
a) Confusion Matrix (за spam като positive клас):
- TP = 30 (spam → spam)
- TN = 150 (не-spam → не-spam)
- FP = 10 (не-spam → spam)
- FN = 10 (spam → не-spam)

b) $Precision = \frac{TP}{TP + FP} = \frac{30}{30 + 10} = \frac{30}{40} = 0.75$

c) $Recall = \frac{TP}{TP + FN} = \frac{30}{30 + 10} = \frac{30}{40} = 0.75$

## Решение 4
$F_1 = 2 \cdot \frac{0.8 \cdot 0.6}{0.8 + 0.6} = 2 \cdot \frac{0.48}{1.4} = \frac{0.96}{1.4} \approx 0.686$

## Решение 5
a) Модел 1: $\frac{950}{1000} = 95\%$

b) Модел 2: $\frac{900 + 40}{1000} = \frac{940}{1000} = 94\%$

c) Модел 2 е по-полезен, въпреки по-ниската accuracy. Модел 1 не открива нито един пример от клас B, докато Модел 2 открива 40 от 50 (80% recall за B).

## Решение 6
- Training: $10000 \times 0.70 = 7000$
- Validation: $10000 \times 0.15 = 1500$
- Test: $10000 \times 0.15 = 1500$

## Решение 7
$L = -[1 \cdot \log(0.8) + 0 \cdot \log(0.2)]$
$L = -\log(0.8) = -(-0.223) = 0.223$

## Решение 8
- **Модел A:** Добър баланс — ниска train и test грешка, малка разлика
- **Модел B:** High variance (overfitting) — много ниска train грешка, висока test грешка
- **Модел C:** High bias (underfitting) — висока грешка и на train, и на test

## Решение 9
a) Размерност на един вектор: 5000

b) Размерност на матрицата: $1000 \times 5000 = 5,000,000$ елемента

c) Процент нули: $\frac{5000 - 50}{5000} = \frac{4950}{5000} = 99\%$

## Решение 10
При stratified split пропорцията се запазва (80% positive, 20% negative).

a) Training set (80% от данните):
- Positive: $800 \times 0.8 = 640$
- Negative: $200 \times 0.8 = 160$

b) Test set (20% от данните):
- Positive: $800 \times 0.2 = 160$
- Negative: $200 \times 0.2 = 40$
