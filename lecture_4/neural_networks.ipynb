{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –õ–µ–∫—Ü–∏—è 4: –ù–µ–≤—Ä–æ–Ω–Ω–∏ –º—Ä–µ–∂–∏\n",
    "\n",
    "## –û—Ç –ª–∏–Ω–µ–π–Ω–∏ –º–æ–¥–µ–ª–∏ –∫—ä–º deep learning\n",
    "\n",
    "**–ü—Ä–æ–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–æ—Å—Ç:** 2-2.5 —á–∞—Å–∞  \n",
    "**–ü—Ä–µ–¥–ø–æ—Å—Ç–∞–≤–∫–∞:** –õ–µ–∫—Ü–∏—è 3 (–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è), –æ—Å–Ω–æ–≤–∏ –Ω–∞ calculus –∏ linear algebra  \n",
    "**–°–ª–µ–¥–≤–∞—â–∞ –ª–µ–∫—Ü–∏—è:** Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. –ú–æ—Ç–∏–≤–∞—Ü–∏—è: –ó–∞—â–æ –ª–∏–Ω–µ–π–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏ –Ω–µ –¥–æ—Å—Ç–∏–≥–∞—Ç?\n",
    "\n",
    "### –ö–∞–∫–≤–æ –Ω–∞—É—á–∏—Ö–º–µ –¥–æ—Å–µ–≥–∞?\n",
    "\n",
    "–í **–õ–µ–∫—Ü–∏—è 1** –≤–∏–¥—è—Ö–º–µ:\n",
    "- Logistic regression –∑–∞ sentiment analysis\n",
    "- Bag-of-words –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–µ\n",
    "- –õ–∏–Ω–µ–π–Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞ –∑–∞ –∫–ª–∞—Å–∏—Ñ–∏–∫–∞—Ü–∏—è\n",
    "\n",
    "–í **–õ–µ–∫—Ü–∏—è 2** –≤–∏–¥—è—Ö–º–µ:\n",
    "- Word2Vec embeddings\n",
    "- –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏ –≤—Ä—ä–∑–∫–∏ –º–µ–∂–¥—É –¥—É–º–∏\n",
    "- –ü–ª—ä—Ç–Ω–∏ (dense) –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–∏—è\n",
    "\n",
    "–í **–õ–µ–∫—Ü–∏—è 3** –≤–∏–¥—è—Ö–º–µ:\n",
    "- Byte-Pair Encoding (BPE)\n",
    "- –ö–∞–∫ —Å—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ LLM —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–∞—Ç —Ç–µ–∫—Å—Ç\n",
    "\n",
    "### –ü—Ä–æ–±–ª–µ–º—ä—Ç —Å –ª–∏–Ω–µ–π–Ω–∏—Ç–µ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "**–õ–∏–Ω–µ–µ–Ω –º–æ–¥–µ–ª:**\n",
    "$$\\hat{y} = \\sigma(\\mathbf{w}^T\\mathbf{x} + b)$$\n",
    "\n",
    "**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**\n",
    "\n",
    "‚ùå **–ù–µ –º–æ–∂–µ –¥–∞ —É–ª–æ–≤–∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –º–µ–∂–¥—É features**\n",
    "- \"not\" + \"good\" —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–µ —Ç—Ä–µ—Ç–∏—Ä–∞—Ç –∑–∞–µ–¥–Ω–æ\n",
    "- –õ–∏–Ω–µ–π–Ω–∏—è—Ç –º–æ–¥–µ–ª –≥–∏ –≤–∏–∂–¥–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ\n",
    "\n",
    "‚ùå **–°–∞–º–æ –µ–¥–Ω–∞ –ª–∏–Ω–µ–π–Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞**\n",
    "- –ù–µ –º–æ–∂–µ –¥–∞ —Ä–∞–∑–¥–µ–ª–∏ —Å–ª–æ–∂–Ω–∏ –º–æ–¥–µ–ª–∏ (XOR –ø—Ä–æ–±–ª–µ–º)\n",
    "\n",
    "‚ùå **–ù—è–º–∞ –π–µ—Ä–∞—Ä—Ö–∏—è –Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–∏—è**\n",
    "- –ù–µ –º–æ–∂–µ –¥–∞ –Ω–∞—É—á–∏ –Ω–∏–≤–∞ –Ω–∞ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è\n",
    "- Low-level features ‚Üí Mid-level features ‚Üí High-level features\n",
    "\n",
    "‚ùå **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ –∏–∑—Ä–∞–∑–∏—Ç–µ–ª–Ω–æ—Å—Ç**\n",
    "- –°–ª–æ–∂–Ω–∏ —Ç–µ–∫—Å—Ç–æ–≤–∏ –º–æ–¥–µ–ª–∏ –∏–∑–∏—Å–∫–≤–∞—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç\n",
    "\n",
    "### –ö–∞–∫–≤–æ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç –Ω–µ–≤—Ä–æ–Ω–Ω–∏—Ç–µ –º—Ä–µ–∂–∏?\n",
    "\n",
    "‚úÖ **–ù–µ–ª–∏–Ω–µ–π–Ω–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏**\n",
    "- Activation functions –¥–æ–±–∞–≤—è—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç\n",
    "\n",
    "‚úÖ **–ô–µ—Ä–∞—Ä—Ö–∏—è –Ω–∞ –Ω–∞—É—á–µ–Ω–∏ features**\n",
    "- –°–ª–æ–π 1: –ø—Ä–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ (edges, colors)\n",
    "- –°–ª–æ–π 2: –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ (shapes, patterns)\n",
    "- –°–ª–æ–π 3: —Å–ª–æ–∂–Ω–∏ –∫–æ–Ω—Ü–µ–ø—Ç–∏ (objects, sentiment)\n",
    "\n",
    "‚úÖ **Universal approximation**\n",
    "- –¢–µ–æ—Ä–µ—Ç–∏—á–Ω–æ –º–æ–∂–µ –¥–∞ –∞–ø—Ä–æ–∫—Å–∏–º–∏—Ä–∞ –≤—Å—è–∫–∞ –Ω–µ–ø—Ä–µ–∫—ä—Å–Ω–∞—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è\n",
    "\n",
    "‚úÖ **–ö–æ–º–ø–æ–∑–∏—Ü–∏—è –Ω–∞ –ø—Ä–æ—Å—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ ‚Üí —Å–ª–æ–∂–Ω–æ –ø–æ–≤–µ–¥–µ–Ω–∏–µ**\n",
    "- –ú–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏, —Å—Ç–∞–∫–Ω–∞—Ç–∏ –∑–∞–µ–¥–Ω–æ\n",
    "\n",
    "### –û—Ç –º–∞–ª–∫–∏ –º—Ä–µ–∂–∏ –∫—ä–º LLM\n",
    "\n",
    "**–ü—ä—Ç—è—Ç:**\n",
    "```\n",
    "–ü—Ä–æ—Å—Ç–∏ –Ω–µ–≤—Ä–æ–Ω–Ω–∏ –º—Ä–µ–∂–∏ (—Ç–∞–∑–∏ –ª–µ–∫—Ü–∏—è)\n",
    "  ‚Üì\n",
    "–†–µ–∫—É—Ä–µ–Ω—Ç–Ω–∏ –º—Ä–µ–∂–∏ (RNN) - –æ–ø–∏—Ç, –Ω–æ –ø—Ä–æ–≤–∞–ª\n",
    "  ‚Üì\n",
    "Transformers (–õ–µ–∫—Ü–∏—è 5)\n",
    "  ‚Üì\n",
    "–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏ –º–æ–¥–µ–ª–∏ - BERT, GPT (–õ–µ–∫—Ü–∏—è 6)\n",
    "  ‚Üì\n",
    "–ú–∞—â–∞–±–∏—Ä–∞–Ω–µ - –º–∏–ª–∏–∞—Ä–¥–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (–õ–µ–∫—Ü–∏—è 7)\n",
    "  ‚Üì\n",
    "Alignment - RLHF (–õ–µ–∫—Ü–∏—è 8)\n",
    "```\n",
    "\n",
    "**–í–∞–∂–Ω–æ:** –í—Å–∏—á–∫–æ, –∫–æ–µ—Ç–æ –Ω–∞—É—á–∏–º –¥–Ω–µ—Å (backpropagation, optimization, training), –≤–∞–∂–∏ –∏ –∑–∞ LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import expit  # sigmoid function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏—Ç–µ\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì –í—Å–∏—á–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Å–∞ –∑–∞—Ä–µ–¥–µ–Ω–∏ —É—Å–ø–µ—à–Ω–æ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è: XOR –ø—Ä–æ–±–ª–µ–º—ä—Ç\n",
    "\n",
    "**XOR (exclusive OR):**\n",
    "- (0, 0) ‚Üí 0\n",
    "- (0, 1) ‚Üí 1\n",
    "- (1, 0) ‚Üí 1\n",
    "- (1, 1) ‚Üí 0\n",
    "\n",
    "**–ü—Ä–æ–±–ª–µ–º:** –ù–µ –µ –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ XOR dataset\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0])\n",
    "\n",
    "# –û–ø–∏—Ç –∑–∞ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ª–∏–Ω–µ–µ–Ω –º–æ–¥–µ–ª\n",
    "linear_model = LogisticRegression()\n",
    "linear_model.fit(X_xor, y_xor)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_pred = linear_model.predict(X_xor)\n",
    "accuracy = np.mean(y_pred == y_xor)\n",
    "\n",
    "print(\"XOR –ü—Ä–æ–±–ª–µ–º\")\n",
    "print(\"=\"*50)\n",
    "print(\"–í—Ö–æ–¥–æ–≤–µ –∏ –µ—Ç–∏–∫–µ—Ç–∏:\")\n",
    "for i, (x, y) in enumerate(zip(X_xor, y_xor)):\n",
    "    pred = y_pred[i]\n",
    "    status = \"‚úì\" if pred == y else \"‚úó\"\n",
    "    print(f\"  {status} x={x} ‚Üí y={y}, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ={pred}\")\n",
    "\n",
    "print(f\"\\n–¢–æ—á–Ω–æ—Å—Ç –Ω–∞ –ª–∏–Ω–µ–π–Ω–∏—è –º–æ–¥–µ–ª: {accuracy:.0%}\")\n",
    "print(\"\\nüí° –õ–∏–Ω–µ–π–Ω–∏—è—Ç –º–æ–¥–µ–ª –Ω–µ –º–æ–∂–µ –¥–∞ —Ä–µ—à–∏ XOR!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ XOR –ø—Ä–æ–±–ª–µ–º–∞\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# XOR –¥–∞–Ω–Ω–∏\n",
    "colors = ['red' if y == 0 else 'blue' for y in y_xor]\n",
    "ax1.scatter(X_xor[:, 0], X_xor[:, 1], c=colors, s=200, edgecolors='black', linewidth=2)\n",
    "ax1.set_xlabel('x‚ÇÅ', fontsize=12)\n",
    "ax1.set_ylabel('x‚ÇÇ', fontsize=12)\n",
    "ax1.set_title('XOR –ü—Ä–æ–±–ª–µ–º: –ù–µ –µ –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º', fontsize=14, pad=15)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xlim(-0.5, 1.5)\n",
    "ax1.set_ylim(-0.5, 1.5)\n",
    "\n",
    "# –î–æ–±–∞–≤—è–º–µ –µ—Ç–∏–∫–µ—Ç–∏\n",
    "for i, (x, y) in enumerate(zip(X_xor, y_xor)):\n",
    "    ax1.annotate(f'y={y}', (x[0], x[1]), xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "# –ù–µ–ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º–∞ –∑–∞–¥–∞—á–∞ (–∫—Ä—ä–≥–æ–≤–µ)\n",
    "X_circles, y_circles = make_circles(n_samples=200, noise=0.1, factor=0.4, random_state=42)\n",
    "colors_circles = ['red' if y == 0 else 'blue' for y in y_circles]\n",
    "ax2.scatter(X_circles[:, 0], X_circles[:, 1], c=colors_circles, s=30, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax2.set_xlabel('x‚ÇÅ', fontsize=12)\n",
    "ax2.set_ylabel('x‚ÇÇ', fontsize=12)\n",
    "ax2.set_title('–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—á–Ω–∏ –∫—Ä—ä–≥–æ–≤–µ: –°—ä—â–æ –Ω–µ–ª–∏–Ω–µ–π–Ω–∞ –∑–∞–¥–∞—á–∞', fontsize=14, pad=15)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° –ß–µ—Ä–≤–µ–Ω–∏—Ç–µ –∏ —Å–∏–Ω–∏—Ç–µ —Ç–æ—á–∫–∏ –Ω–µ –º–æ–≥–∞—Ç –¥–∞ –±—ä–¥–∞—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏ —Å –ø—Ä–∞–≤–∞ –ª–∏–Ω–∏—è!\")\n",
    "print(\"   –ù–µ–æ–±—Ö–æ–¥–∏–º–∞ –µ –Ω–µ–ª–∏–Ω–µ–π–Ω–∞ –≥—Ä–∞–Ω–∏—Ü–∞ ‚Üí –ù–µ–≤—Ä–æ–Ω–Ω–∏ –º—Ä–µ–∂–∏!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. –ì—Ä–∞–¥–∏–≤–Ω–∏ –µ–ª–µ–º–µ–Ω—Ç–∏: –ù–µ–≤—Ä–æ–Ω–∏ –∏ —Å–ª–æ–µ–≤–µ\n",
    "\n",
    "### 2.1 –ï–¥–∏–Ω–∏—á–µ–Ω –Ω–µ–≤—Ä–æ–Ω\n",
    "\n",
    "**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–æ–¥–µ–ª:**\n",
    "\n",
    "1. **–õ–∏–Ω–µ–π–Ω–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è:**\n",
    "$$z = \\sum_{i=1}^{n} w_i x_i + b = \\mathbf{w}^T\\mathbf{x} + b$$\n",
    "\n",
    "2. **–ê–∫—Ç–∏–≤–∞—Ü–∏—è:**\n",
    "$$a = f(z)$$\n",
    "\n",
    "–ö—ä–¥–µ—Ç–æ:\n",
    "- $\\mathbf{x}$ = –≤—Ö–æ–¥–µ–Ω –≤–µ–∫—Ç–æ—Ä\n",
    "- $\\mathbf{w}$ = —Ç–µ–≥–ª–∞ (weights)\n",
    "- $b$ = bias\n",
    "- $f$ = activation function\n",
    "- $a$ = –∏–∑—Ö–æ–¥–Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏—è\n",
    "\n",
    "**–ë–∏–æ–ª–æ–≥–∏—á–Ω–∞ –∏–Ω—Å–ø–∏—Ä–∞—Ü–∏—è:**\n",
    "- –ù–µ–≤—Ä–æ–Ω –≤ –º–æ–∑—ä–∫–∞ –ø–æ–ª—É—á–∞–≤–∞ —Å–∏–≥–Ω–∞–ª–∏ –æ—Ç –¥—Ä—É–≥–∏ –Ω–µ–≤—Ä–æ–Ω–∏\n",
    "- –ê–∫–æ —Å—É–º–∞—Ç–∞ –Ω–∞ —Å–∏–≥–Ω–∞–ª–∏—Ç–µ –Ω–∞–¥—Ö–≤—ä—Ä–ª–∏ –ø—Ä–∞–≥ ‚Üí –Ω–µ–≤—Ä–æ–Ω \"—Å–µ –∞–∫—Ç–∏–≤–∏—Ä–∞\"\n",
    "- –ò–∑–∫—É—Å—Ç–≤–µ–Ω–∏—è—Ç –Ω–µ–≤—Ä–æ–Ω –µ **–º–Ω–æ–≥–æ –æ–ø—Ä–æ—Å—Ç–µ–Ω** –º–æ–¥–µ–ª\n",
    "\n",
    "### 2.2 –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "\n",
    "**–ó–∞—â–æ —Å–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∏?**\n",
    "\n",
    "–ë–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü–∏—è:\n",
    "$$f(W_2 \\cdot f(W_1 \\cdot x)) = f(W_2 \\cdot W_1 \\cdot x) = f(W \\cdot x)$$\n",
    "\n",
    "–ú—Ä–µ–∂–∞—Ç–∞ —Å–µ –∫–æ–ª–∞–ø—Å–∏—Ä–∞ –¥–æ –ª–∏–Ω–µ–µ–Ω –º–æ–¥–µ–ª!\n",
    "\n",
    "**–ü–æ–ø—É–ª—è—Ä–Ω–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏:**\n",
    "\n",
    "#### 1. Sigmoid\n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "- **–ò–∑—Ö–æ–¥:** (0, 1)\n",
    "- **–ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ:** Output layer –∑–∞ binary classification\n",
    "- **–ü—Ä–æ–±–ª–µ–º:** Vanishing gradients\n",
    "\n",
    "#### 2. Tanh\n",
    "$$\\tanh(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$$\n",
    "\n",
    "- **–ò–∑—Ö–æ–¥:** (-1, 1)\n",
    "- **–ü—Ä–µ–¥–∏–º—Å—Ç–≤–æ:** Zero-centered (–ø–æ-–¥–æ–±—Ä–µ –æ—Ç sigmoid)\n",
    "- **–ü—Ä–æ–±–ª–µ–º:** –°—ä—â–æ vanishing gradients\n",
    "\n",
    "#### 3. ReLU (Rectified Linear Unit)\n",
    "$$\\text{ReLU}(z) = \\max(0, z)$$\n",
    "\n",
    "- **–ò–∑—Ö–æ–¥:** [0, ‚àû)\n",
    "- **–ü—Ä–µ–¥–∏–º—Å—Ç–≤–∞:**\n",
    "  - –†–µ—à–∞–≤–∞ vanishing gradient –ø—Ä–æ–±–ª–µ–º–∞\n",
    "  - –ë—ä—Ä–∑–æ –∏–∑—á–∏—Å–ª–µ–Ω–∏–µ\n",
    "  - –ù–∞–π-–ø–æ–ø—É–ª—è—Ä–Ω–∞ –≤ —Å—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ –º—Ä–µ–∂–∏\n",
    "- **–ü—Ä–æ–±–ª–µ–º:** \"Dead ReLU\" (–Ω–µ–≤—Ä–æ–Ω–∏ –º–æ–≥–∞—Ç –¥–∞ —É–º—Ä–∞—Ç)\n",
    "\n",
    "#### 4. GELU (Gaussian Error Linear Unit)\n",
    "$$\\text{GELU}(z) \\approx z \\cdot \\sigma(1.702z)$$\n",
    "\n",
    "- **–ò–∑–ø–æ–ª–∑–≤–∞ —Å–µ –≤:** GPT-2, GPT-3, BERT\n",
    "- **–ü—Ä–µ–¥–∏–º—Å—Ç–≤–∞:** Smooth approximation –Ω–∞ ReLU\n",
    "- State-of-the-art –∑–∞ Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def gelu(z):\n",
    "    # GELU approximation\n",
    "    return 0.5 * z * (1 + np.tanh(np.sqrt(2 / np.pi) * (z + 0.044715 * z**3)))\n",
    "\n",
    "# –ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∏ (derivatives)\n",
    "def sigmoid_derivative(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh_derivative(z):\n",
    "    return 1 - np.tanh(z)**2\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "print(\"‚úì –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–∏!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Sigmoid\n",
    "axes[0, 0].plot(z, sigmoid(z), 'b-', linewidth=2, label='sigmoid(z)')\n",
    "axes[0, 0].plot(z, sigmoid_derivative(z), 'r--', linewidth=2, label=\"sigmoid'(z)\")\n",
    "axes[0, 0].axhline(y=0, color='k', linewidth=0.5)\n",
    "axes[0, 0].axvline(x=0, color='k', linewidth=0.5)\n",
    "axes[0, 0].set_title('Sigmoid', fontsize=14, pad=10)\n",
    "axes[0, 0].set_xlabel('z')\n",
    "axes[0, 0].set_ylabel('Activation')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].text(0.05, 0.95, '–ò–∑—Ö–æ–¥: (0, 1)\\nVanishing gradients', \n",
    "                transform=axes[0, 0].transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Tanh\n",
    "axes[0, 1].plot(z, tanh(z), 'b-', linewidth=2, label='tanh(z)')\n",
    "axes[0, 1].plot(z, tanh_derivative(z), 'r--', linewidth=2, label=\"tanh'(z)\")\n",
    "axes[0, 1].axhline(y=0, color='k', linewidth=0.5)\n",
    "axes[0, 1].axvline(x=0, color='k', linewidth=0.5)\n",
    "axes[0, 1].set_title('Tanh', fontsize=14, pad=10)\n",
    "axes[0, 1].set_xlabel('z')\n",
    "axes[0, 1].set_ylabel('Activation')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].text(0.05, 0.95, '–ò–∑—Ö–æ–¥: (-1, 1)\\nZero-centered', \n",
    "                transform=axes[0, 1].transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# ReLU\n",
    "axes[1, 0].plot(z, relu(z), 'b-', linewidth=2, label='ReLU(z)')\n",
    "axes[1, 0].plot(z, relu_derivative(z), 'r--', linewidth=2, label=\"ReLU'(z)\")\n",
    "axes[1, 0].axhline(y=0, color='k', linewidth=0.5)\n",
    "axes[1, 0].axvline(x=0, color='k', linewidth=0.5)\n",
    "axes[1, 0].set_title('ReLU', fontsize=14, pad=10)\n",
    "axes[1, 0].set_xlabel('z')\n",
    "axes[1, 0].set_ylabel('Activation')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].text(0.05, 0.95, '–ò–∑—Ö–æ–¥: [0, ‚àû)\\n–ù–∞–π-–ø–æ–ø—É–ª—è—Ä–Ω–∞!', \n",
    "                transform=axes[1, 0].transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "# GELU\n",
    "axes[1, 1].plot(z, gelu(z), 'b-', linewidth=2, label='GELU(z)')\n",
    "axes[1, 1].plot(z, relu(z), 'g--', linewidth=1, alpha=0.5, label='ReLU (–∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)')\n",
    "axes[1, 1].axhline(y=0, color='k', linewidth=0.5)\n",
    "axes[1, 1].axvline(x=0, color='k', linewidth=0.5)\n",
    "axes[1, 1].set_title('GELU', fontsize=14, pad=10)\n",
    "axes[1, 1].set_xlabel('z')\n",
    "axes[1, 1].set_ylabel('Activation')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].text(0.05, 0.95, 'Smooth ReLU\\n–ò–∑–ø–æ–ª–∑–≤–∞ —Å–µ –≤ GPT!', \n",
    "                transform=axes[1, 1].transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° –ù–∞–±–ª—é–¥–µ–Ω–∏—è:\")\n",
    "print(\"   ‚Ä¢ Sigmoid –∏ Tanh: –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—Ç–∞ –∫–ª–æ–Ω–∏ –∫—ä–º 0 –ø—Ä–∏ –≥–æ–ª–µ–º–∏ |z| ‚Üí vanishing gradients\")\n",
    "print(\"   ‚Ä¢ ReLU: –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—Ç–∞ –µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ (1) –∑–∞ z > 0 ‚Üí –Ω—è–º–∞ vanishing gradients\")\n",
    "print(\"   ‚Ä¢ GELU: smooth –≤–µ—Ä—Å–∏—è –Ω–∞ ReLU, –∏–∑–ø–æ–ª–∑–≤–∞ —Å–µ –≤ —Å—ä–≤—Ä–µ–º–µ–Ω–Ω–∏—Ç–µ LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 –°–ª–æ–µ–≤–µ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞\n",
    "\n",
    "**–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞ –Ω–µ–≤—Ä–æ–Ω–Ω–∞ –º—Ä–µ–∂–∞:**\n",
    "\n",
    "```\n",
    "Input Layer     Hidden Layer 1    Hidden Layer 2    Output Layer\n",
    "    x‚ÇÅ              h‚ÇÅ‚ÅΩ¬π‚Åæ             h‚ÇÅ‚ÅΩ¬≤‚Åæ              ≈∑\n",
    "    x‚ÇÇ     ‚Üí        h‚ÇÇ‚ÅΩ¬π‚Åæ      ‚Üí      h‚ÇÇ‚ÅΩ¬≤‚Åæ       ‚Üí   \n",
    "    x‚ÇÉ              h‚ÇÉ‚ÅΩ¬π‚Åæ             h‚ÇÉ‚ÅΩ¬≤‚Åæ            \n",
    "    x‚ÇÑ              h‚ÇÑ‚ÅΩ¬π‚Åæ                              \n",
    "```\n",
    "\n",
    "**–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è:**\n",
    "- **Input layer:** –ü–æ–ª—É—á–∞–≤–∞ –≤—Ö–æ–¥–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏ (embeddings –∑–∞ NLP)\n",
    "- **Hidden layers:** –ù–∞—É—á–µ–Ω–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤—è–Ω–∏—è (–º–æ–∂–µ –¥–∞ –∏–º–∞ –º–Ω–æ–≥–æ)\n",
    "- **Output layer:** –§–∏–Ω–∞–ª–Ω–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (task-specific)\n",
    "\n",
    "**Fully Connected (Dense) Layer:**\n",
    "- –í—Å–µ–∫–∏ –Ω–µ–≤—Ä–æ–Ω —Å–µ —Å–≤—ä—Ä–∑–≤–∞ —Å **–≤—Å–∏—á–∫–∏** –Ω–µ–≤—Ä–æ–Ω–∏ –æ—Ç –ø—Ä–µ–¥–∏—à–Ω–∏—è —Å–ª–æ–π\n",
    "- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏: $W^{[l]} \\in \\mathbb{R}^{n_l \\times n_{l-1}}$ –∏ $b^{[l]} \\in \\mathbb{R}^{n_l}$\n",
    "\n",
    "**–ù–æ—Ç–∞—Ü–∏—è:**\n",
    "- –°–ª–æ–π $l$ –∏–º–∞ $n_l$ –Ω–µ–≤—Ä–æ–Ω–∞\n",
    "- $W^{[l]}$ = –º–∞—Ç—Ä–∏—Ü–∞ —Å —Ç–µ–≥–ª–∞\n",
    "- $b^{[l]}$ = bias –≤–µ–∫—Ç–æ—Ä\n",
    "- $a^{[l]}$ = –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –Ω–∞ —Å–ª–æ–π $l$\n",
    "- $z^{[l]}$ = –ª–∏–Ω–µ–π–Ω–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –ø—Ä–µ–¥–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è\n",
    "\n",
    "### –ü—Ä–∏–º–µ—Ä: Sentiment Classification –º—Ä–µ–∂–∞\n",
    "\n",
    "**–ó–∞–¥–∞—á–∞:** –ö–ª–∞—Å–∏—Ñ–∏—Ü–∏—Ä–∞–Ω–µ –Ω–∞ —Ñ–∏–ª–º–æ–≤–∏ —Ä–µ–≤—é—Ç–∞ (–ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–æ/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª–Ω–æ)\n",
    "\n",
    "**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**\n",
    "```\n",
    "Input: Averaged Word2Vec (300 dimensions)\n",
    "  ‚Üì\n",
    "Dense Layer 1: 300 ‚Üí 128 (ReLU)\n",
    "  ‚Üì\n",
    "Dense Layer 2: 128 ‚Üí 64 (ReLU)\n",
    "  ‚Üì\n",
    "Output Layer: 64 ‚Üí 1 (Sigmoid)\n",
    "```\n",
    "\n",
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏:**\n",
    "- Layer 1: $300 \\times 128 + 128 = 38,528$\n",
    "- Layer 2: $128 \\times 64 + 64 = 8,256$\n",
    "- Output: $64 \\times 1 + 1 = 65$\n",
    "- **–û–±—â–æ:** 46,849 –ø–∞—Ä–∞–º–µ—Ç—Ä–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞ –º—Ä–µ–∂–∞\n",
    "def visualize_network_architecture():\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # –ü–æ–∑–∏—Ü–∏–∏ –Ω–∞ —Å–ª–æ–µ–≤–µ—Ç–µ\n",
    "    layers = [4, 6, 4, 1]  # –ë—Ä–æ–π –Ω–µ–≤—Ä–æ–Ω–∏ –≤—ä–≤ –≤—Å–µ–∫–∏ —Å–ª–æ–π\n",
    "    layer_names = ['Input\\nLayer', 'Hidden\\nLayer 1', 'Hidden\\nLayer 2', 'Output\\nLayer']\n",
    "    layer_positions = [1, 3, 5, 7]\n",
    "    \n",
    "    # –†–∏—Å—É–≤–∞–º–µ –Ω–µ–≤—Ä–æ–Ω–∏—Ç–µ\n",
    "    neuron_positions = {}\n",
    "    for layer_idx, (n_neurons, x_pos) in enumerate(zip(layers, layer_positions)):\n",
    "        y_positions = np.linspace(1, 8, n_neurons)\n",
    "        neuron_positions[layer_idx] = []\n",
    "        for y_pos in y_positions:\n",
    "            circle = plt.Circle((x_pos, y_pos), 0.2, color='lightblue', ec='black', linewidth=2)\n",
    "            ax.add_patch(circle)\n",
    "            neuron_positions[layer_idx].append((x_pos, y_pos))\n",
    "    \n",
    "    # –†–∏—Å—É–≤–∞–º–µ –≤—Ä—ä–∑–∫–∏—Ç–µ (—Å–∞–º–æ –Ω—è–∫–æ–ª–∫–æ –∑–∞ —è—Å–Ω–æ—Ç–∞)\n",
    "    for layer_idx in range(len(layers) - 1):\n",
    "        for i, (x1, y1) in enumerate(neuron_positions[layer_idx]):\n",
    "            for j, (x2, y2) in enumerate(neuron_positions[layer_idx + 1]):\n",
    "                # –†–∏—Å—É–≤–∞–º–µ —Å–∞–º–æ —á–∞—Å—Ç –æ—Ç –≤—Ä—ä–∑–∫–∏—Ç–µ –∑–∞ —è—Å–Ω–æ—Ç–∞\n",
    "                if i % 2 == 0 or j % 2 == 0:\n",
    "                    ax.plot([x1, x2], [y1, y2], 'gray', alpha=0.3, linewidth=0.5)\n",
    "    \n",
    "    # –î–æ–±–∞–≤—è–º–µ –µ—Ç–∏–∫–µ—Ç–∏\n",
    "    for i, (name, x_pos) in enumerate(zip(layer_names, layer_positions)):\n",
    "        ax.text(x_pos, 0.3, name, ha='center', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # –î–æ–±–∞–≤—è–º–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ —Ä–∞–∑–º–µ—Ä–∏—Ç–µ\n",
    "        if i == 0:\n",
    "            ax.text(x_pos, -0.3, '300d', ha='center', fontsize=10, style='italic')\n",
    "        elif i == 1:\n",
    "            ax.text(x_pos, -0.3, '128 neurons', ha='center', fontsize=10, style='italic')\n",
    "        elif i == 2:\n",
    "            ax.text(x_pos, -0.3, '64 neurons', ha='center', fontsize=10, style='italic')\n",
    "        else:\n",
    "            ax.text(x_pos, -0.3, 'probability', ha='center', fontsize=10, style='italic')\n",
    "    \n",
    "    # –î–æ–±–∞–≤—è–º–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "    ax.text(2, 9, 'ReLU', ha='center', fontsize=11, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    ax.text(4, 9, 'ReLU', ha='center', fontsize=11, bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    ax.text(6, 9, 'Sigmoid', ha='center', fontsize=11, bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))\n",
    "    \n",
    "    ax.set_xlim(0, 8)\n",
    "    ax.set_ylim(-1, 9.5)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Sentiment Classification Neural Network Architecture', fontsize=16, pad=20, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_network_architecture()\n",
    "\n",
    "print(\"üí° –í—Å—è–∫–∞ –ª–∏–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–≤–∞ –µ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—ä—Ä (weight).\")\n",
    "print(\"   Fully connected –æ–∑–Ω–∞—á–∞–≤–∞: –≤—Å–µ–∫–∏ –Ω–µ–≤—Ä–æ–Ω –µ —Å–≤—ä—Ä–∑–∞–Ω —Å –≤—Å–∏—á–∫–∏ –Ω–µ–≤—Ä–æ–Ω–∏ –æ—Ç –ø—Ä–µ–¥–∏—à–Ω–∏—è —Å–ª–æ–π.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
