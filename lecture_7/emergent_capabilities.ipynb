{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 7: Емерджентни способности при мащаб\n",
    "\n",
    "**Продължителност:** 2-2.5 часа  \n",
    "**Предпоставки:** Лекция 6 (Фундаментални модели, Scaling Laws)  \n",
    "**Следваща лекция:** Alignment и RLHF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Цели на лекцията\n",
    "\n",
    "След тази лекция ще можете:\n",
    "\n",
    "- Обяснявате какво е emergence и защо е изненадващо\n",
    "- Разбирате zero-shot и few-shot learning като нова парадигма\n",
    "- Анализирате кои способности се появяват при мащаб и кога\n",
    "- Оценявате критично дебата за \"острото\" vs \"гладко\" emergence\n",
    "- Идентифицирате какво **не** се подобрява с мащаба"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пътна карта\n",
    "\n",
    "```\n",
    "1. Какво е emergence? → 2. Zero/Few-shot Learning → 3. Механика на ICL\n",
    "       ↓\n",
    "4. Emergent Reasoning → 5. Как измерваме? → 6. Какво НЕ emerge?\n",
    "       ↓\n",
    "7. Теории защо се случва → 8. Implications → 9. Обобщение\n",
    "```\n",
    "\n",
    "**Стил на лекцията:** Дискусия и примери. Минимален код — фокус върху разбиране на феномените."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Минимални импорти за визуализации\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Готови за дискусия!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Какво е Emergence?\n",
    "\n",
    "### Recap от Лекция 6\n",
    "\n",
    "В предишната лекция видяхме:\n",
    "- **Scaling laws:** Loss намалява предвидимо с compute\n",
    "- **Данни:** Трилиони токени от интернета\n",
    "- **Objective:** Предвиждане на следващия токен\n",
    "\n",
    "**Но:** Scaling laws описват само loss. Какво става със **способностите**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дефиниция на Emergence\n",
    "\n",
    "> **Emergence:** Способности, които се появяват при определен мащаб, без да са били явно тренирани.\n",
    "\n",
    "**Три ключови характеристики:**\n",
    "\n",
    "| Характеристика | Описание |\n",
    "|----------------|----------|\n",
    "| **Неочаквани** | Не следват директно от training objective |\n",
    "| **Качествен скок** | Не просто \"по-добро\", а \"ново\" |\n",
    "| **Threshold ефект** | Появяват се при определен размер |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примери, които изненадаха изследователите\n",
    "\n",
    "**GPT-3 (2020) демонстрира способности, които никой не е тренирал:**\n",
    "\n",
    "| Способност | Пример | Защо е изненадващо |\n",
    "|------------|--------|--------------------|\n",
    "| **Few-shot learning** | 3 примера → научава задачата | Без gradient updates! |\n",
    "| **Arithmetic** | \"25 + 37 = ?\" → \"62\" | Не е калкулатор! |\n",
    "| **Code generation** | Описание → Python код | Учен предимно на текст |\n",
    "| **Translation** | Превежда езици с малко данни | Без parallel corpora |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Централната мистерия\n",
    "\n",
    "> **Въпрос:** Защо предвиждането на следващия токен води до reasoning?\n",
    "\n",
    "**Хипотеза за компресия:**\n",
    "\n",
    "За да предвидиш добре следващата дума, трябва да разбереш:\n",
    "- Граматика\n",
    "- Семантика\n",
    "- Логика\n",
    "- Факти за света\n",
    "\n",
    "\"Компресията изисква разбиране.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: Какво трябва да \"знае\" моделът\n",
    "\n",
    "За да предвиди следващата дума в:\n",
    "\n",
    "```\n",
    "\"Столицата на България е ___\"\n",
    "```\n",
    "\n",
    "Моделът трябва да знае:\n",
    "1. Граматика: очаква се съществително\n",
    "2. Семантика: става въпрос за столица\n",
    "3. Факт: столицата на България е София\n",
    "\n",
    "**Next-token prediction имплицитно изисква world knowledge!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Zero-Shot и Few-Shot Learning\n",
    "\n",
    "### Старата парадигма (преди 2020)\n",
    "\n",
    "```\n",
    "Task A → Train Model A (с много labeled data)\n",
    "Task B → Train Model B (с много labeled data)\n",
    "Task C → Train Model C (с много labeled data)\n",
    "```\n",
    "\n",
    "**Проблеми:**\n",
    "- Нужни са хиляди примери per task\n",
    "- Отделен модел за всяка задача\n",
    "- Не генерализира към нови задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Новата парадигма: In-Context Learning\n",
    "\n",
    "```\n",
    "Task A ─┐\n",
    "Task B ─┼─→ Един Foundation Model ─→ Всички задачи\n",
    "Task C ─┘\n",
    "```\n",
    "\n",
    "**Ключова разлика:**\n",
    "- **Без gradient updates** при inference\n",
    "- Задачата се \"описва\" в prompt-а\n",
    "- Същият модел, много приложения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot Learning\n",
    "\n",
    "> Само инструкция, без примери.\n",
    "\n",
    "**Пример — sentiment анализ:**\n",
    "\n",
    "```\n",
    "Prompt: \"Classify the sentiment as positive or negative:\n",
    "         Review: The movie was absolutely fantastic!\n",
    "         Sentiment:\"\n",
    "\n",
    "Model output: \"positive\"\n",
    "```\n",
    "\n",
    "**Моделът никога не е виждал тази конкретна инструкция при training!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какво позволява Zero-Shot?\n",
    "\n",
    "| Фактор | Обяснение |\n",
    "|--------|----------|\n",
    "| **Instruction understanding** | Виждал е инструкции в training data |\n",
    "| **Task generalization** | Разбира концепции като \"classify\", \"translate\" |\n",
    "| **World knowledge** | Знае какво значи \"positive sentiment\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot Learning\n",
    "\n",
    "> Няколко примера в prompt-а (обикновено 1-10).\n",
    "\n",
    "**Пример — превод:**\n",
    "\n",
    "```\n",
    "English: Hello → Bulgarian: Здравей\n",
    "English: Thank you → Bulgarian: Благодаря\n",
    "English: Good morning → Bulgarian: _____\n",
    "```\n",
    "\n",
    "**Model output:** \"Добро утро\"\n",
    "\n",
    "Моделът **инферира pattern** от примерите и го прилага!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot: Примери за успех и неуспех\n",
    "\n",
    "**Успех — прост pattern:**\n",
    "\n",
    "```\n",
    "Input: cat → Output: CAT\n",
    "Input: dog → Output: DOG  \n",
    "Input: bird → Output: ___\n",
    "```\n",
    "✓ Моделът разбира: uppercase\n",
    "\n",
    "**Неуспех — сложен/неясен pattern:**\n",
    "\n",
    "```\n",
    "Input: 2 → Output: 4\n",
    "Input: 3 → Output: 9\n",
    "Input: 4 → Output: ___\n",
    "```\n",
    "? Може да е x² или 2x или друго..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling на Few-Shot способности\n",
    "\n",
    "Резултати от GPT-3 paper (Brown et al., 2020):\n",
    "\n",
    "| Размер на модела | Few-shot способност |\n",
    "|------------------|--------------------|\n",
    "| < 1B параметри | Минимална |\n",
    "| 1-10B | Частична, inconsistent |\n",
    "| 10-100B | Силна, подобрява се с k |\n",
    "| > 100B | Близка до fine-tuned модели |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация: Few-shot performance vs model size (стилизирани данни от GPT-3 paper)\n",
    "model_sizes = ['125M', '350M', '1.3B', '2.7B', '6.7B', '13B', '175B']\n",
    "model_params = [0.125, 0.35, 1.3, 2.7, 6.7, 13, 175]\n",
    "\n",
    "# Accuracy на различни benchmarks (приблизителни стойности)\n",
    "zero_shot = [25, 28, 35, 40, 48, 52, 65]\n",
    "one_shot = [27, 32, 42, 48, 55, 60, 72]\n",
    "few_shot = [30, 38, 50, 58, 65, 72, 82]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(model_sizes))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, zero_shot, width, label='Zero-shot', color='#3498db')\n",
    "bars2 = ax.bar(x, one_shot, width, label='One-shot', color='#2ecc71')\n",
    "bars3 = ax.bar(x + width, few_shot, width, label='Few-shot (k=32)', color='#e74c3c')\n",
    "\n",
    "ax.set_xlabel('Размер на модела', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Few-Shot Learning: Performance vs Scale\\n(стилизирани данни от GPT-3)', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_sizes)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Анотация за emergence\n",
    "ax.axvline(x=4, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.text(4.1, 85, 'Emergence\\nthreshold', fontsize=10, color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Забележете: рязко подобрение след 6.7B параметри!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Механика на In-Context Learning\n",
    "\n",
    "### Какво се случва при inference?\n",
    "\n",
    "**Критичен факт:** Теглата на модела са **замразени**!\n",
    "\n",
    "```\n",
    "Training:   Gradient descent → Update weights\n",
    "ICL:        Forward pass only → Same weights\n",
    "```\n",
    "\n",
    "**Въпрос:** Как моделът \"научава\" от примерите без gradient updates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 1: Implicit Fine-Tuning\n",
    "\n",
    "> Attention механизмът имплицитно симулира gradient descent.\n",
    "\n",
    "**Идея (Dai et al., 2022):**\n",
    "- Attention weights създават \"gradient-like\" промени в representations\n",
    "- Transformer-ът е научил да имплементира optimization algorithm\n",
    "\n",
    "**Evidence:** ICL performance корелира с fine-tuning performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 2: Task Recognition\n",
    "\n",
    "> Моделът разпознава типа задача и активира съответните \"circuits\".\n",
    "\n",
    "**Идея:**\n",
    "- При pretraining моделът е виждал подобни patterns\n",
    "- Few-shot примерите служат като \"ключ\" за retrieval\n",
    "- Моделът не учи нова задача, а разпознава позната\n",
    "\n",
    "**Evidence:** ICL работи дори с неправилни labels (Min et al., 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изненадващ резултат: Labels не винаги са важни!\n",
    "\n",
    "**Експеримент (Min et al., 2022):**\n",
    "\n",
    "```\n",
    "Correct labels:              Random labels:\n",
    "positive → positive          positive → negative  \n",
    "negative → negative          negative → positive\n",
    "test → ???                   test → ???\n",
    "```\n",
    "\n",
    "**Резултат:** Performance пада малко, но все още работи!\n",
    "\n",
    "**Извод:** Форматът и input distribution може да са по-важни от label correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 3: Bayesian Inference\n",
    "\n",
    "> Моделът учи distribution над задачи при pretraining.\n",
    "\n",
    "**Идея:**\n",
    "- Pretraining създава implicit prior $P(task)$\n",
    "- Few-shot примерите update-ват posterior $P(task | examples)$\n",
    "- Prediction се базира на most likely task\n",
    "\n",
    "**Evidence:** More examples → better task identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Какво влияе на ICL performance?\n",
    "\n",
    "| Фактор | Ефект |\n",
    "|--------|-------|\n",
    "| **Брой примери** | Повече = по-добре (до лимита на context) |\n",
    "| **Ред на примерите** | Последните имат по-голямо влияние (recency bias) |\n",
    "| **Качество vs количество** | Качеството е по-важно |\n",
    "| **Формат на prompt** | Много влияние (Лекция 10) |\n",
    "| **Task similarity** | По-близки до pretraining = по-добре |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ограничения на ICL\n",
    "\n",
    "| Ограничение | Описание |\n",
    "|-------------|----------|\n",
    "| **Context window** | Не можем да дадем много примери |\n",
    "| **Inconsistency** | Различни runs дават различни резултати |\n",
    "| **Prompt sensitivity** | Малки промени → големи разлики |\n",
    "| **Procedural knowledge** | Не може да научи нови алгоритми |\n",
    "| **Knowledge updates** | Не може да промени вътрешните си знания |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Emergent Reasoning Capabilities\n",
    "\n",
    "### Mathematical Reasoning\n",
    "\n",
    "Едно от най-изненадващите emergent abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K Benchmark\n",
    "\n",
    "**8000 математически задачи на ниво начално училище:**\n",
    "\n",
    "```\n",
    "Question: Janet's ducks lay 16 eggs per day. She eats 3 for breakfast\n",
    "every morning and bakes muffins for her friends every day with 4. \n",
    "She sells the remainder at the farmers' market for $2 per egg.\n",
    "How much does she make every day?\n",
    "\n",
    "Answer: 16 - 3 - 4 = 9 eggs remain\n",
    "        9 × $2 = $18\n",
    "```\n",
    "\n",
    "**Изисква:** Multi-step reasoning, arithmetic, word problem understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K: Performance по мащаб\n",
    "\n",
    "| Модел | Параметри | GSM8K Accuracy |\n",
    "|-------|-----------|----------------|\n",
    "| GPT-2 | 1.5B | ~0% |\n",
    "| GPT-3 | 175B | ~35% |\n",
    "| PaLM | 540B | ~56% |\n",
    "| GPT-4 | ~1T+ (est.) | ~92% |\n",
    "| Claude 3.5 | Unknown | ~96% |\n",
    "\n",
    "**Наблюдение:** Рязък скок около 100B параметри!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация на emergence в математическо reasoning\n",
    "model_sizes_log = [1.5, 13, 175, 540, 1000]  # Billions\n",
    "gsm8k_accuracy = [0, 10, 35, 56, 92]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.semilogx(model_sizes_log, gsm8k_accuracy, 'o-', linewidth=2, markersize=10, color='#e74c3c')\n",
    "\n",
    "# Анотации за модели\n",
    "labels = ['GPT-2\\n(1.5B)', 'GPT-3\\n(13B)', 'GPT-3\\n(175B)', 'PaLM\\n(540B)', 'GPT-4\\n(~1T)']\n",
    "for i, (x, y, label) in enumerate(zip(model_sizes_log, gsm8k_accuracy, labels)):\n",
    "    offset = 10 if i % 2 == 0 else -15\n",
    "    ax.annotate(label, (x, y), textcoords=\"offset points\", xytext=(0, offset),\n",
    "                ha='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Параметри (милиарди, log scale)', fontsize=12)\n",
    "ax.set_ylabel('GSM8K Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Emergence на Mathematical Reasoning\\n(GSM8K benchmark)', fontsize=14)\n",
    "ax.set_ylim(-5, 100)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight emergence zone\n",
    "ax.axvspan(50, 200, alpha=0.2, color='yellow', label='Emergence zone')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: Arithmetic с различни модели\n",
    "\n",
    "**Prompt:** \"What is 47 × 83?\"\n",
    "\n",
    "| Модел | Output | Верен ли е? |\n",
    "|-------|--------|-------------|\n",
    "| Small (1B) | \"47 × 83 is a multiplication...\" | ✗ Не отговаря |\n",
    "| Medium (10B) | \"3801\" | ✗ Грешен |\n",
    "| Large (175B) | \"3901\" | ✓ Верен |\n",
    "\n",
    "**Забележка:** Това не е \"изчисление\" — моделът е научил patterns от training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Reasoning\n",
    "\n",
    "**Syllogisms — какво работи:**\n",
    "\n",
    "```\n",
    "Premise 1: All mammals are warm-blooded.\n",
    "Premise 2: All dogs are mammals.\n",
    "Conclusion: Therefore, all dogs are ___\n",
    "\n",
    "Model: \"warm-blooded\" ✓\n",
    "```\n",
    "\n",
    "**Какво НЕ работи добре:**\n",
    "\n",
    "```\n",
    "Multi-hop reasoning с много стъпки\n",
    "Контрафактуални premises\n",
    "Логически \"traps\" (напр. affirming the consequent)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonsense Reasoning\n",
    "\n",
    "**Physical intuition:**\n",
    "\n",
    "```\n",
    "Q: If I drop a ball, what happens?\n",
    "A: It falls to the ground due to gravity.\n",
    "```\n",
    "✓ Работи — много примери в training data\n",
    "\n",
    "**Social reasoning:**\n",
    "\n",
    "```\n",
    "Q: John gave Mary a gift. How does Mary probably feel?\n",
    "A: Happy, grateful, or pleased.\n",
    "```\n",
    "✓ Работи — social patterns са често срещани\n",
    "\n",
    "**Gradual improvement:** За разлика от math, тук няма \"рязък\" emergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation\n",
    "\n",
    "**HumanEval Benchmark (164 programming problems):**\n",
    "\n",
    "| Модел | Pass@1 |\n",
    "|-------|--------|\n",
    "| Codex (12B) | 28% |\n",
    "| GPT-3.5 | 48% |\n",
    "| GPT-4 | 67% |\n",
    "| Claude 3.5 Sonnet | 92% |\n",
    "\n",
    "**Защо код?**\n",
    "- Код е структурирано reasoning\n",
    "- GitHub е огромен training source\n",
    "- Compilers дават \"ground truth\" feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: Code Generation Evolution\n",
    "\n",
    "**Задача:** Write a function to check if a number is prime.\n",
    "\n",
    "**Small model (1B):**\n",
    "```python\n",
    "def is_prime(n):\n",
    "    # incomplete or syntax errors\n",
    "```\n",
    "\n",
    "**Medium model (10B):**\n",
    "```python\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, n):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "```\n",
    "✓ Работи, но неефективно (O(n))\n",
    "\n",
    "**Large model (175B+):**\n",
    "```python\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "```\n",
    "✓ Оптимизирано (O(√n)), handles edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual Capabilities\n",
    "\n",
    "**Zero-shot cross-lingual transfer:**\n",
    "\n",
    "Модел обучен предимно на английски може да:\n",
    "- Отговаря на въпроси на други езици\n",
    "- Превежда без parallel corpora\n",
    "- Разбира нискоресурсни езици\n",
    "\n",
    "**Ограничения:**\n",
    "- English-centric bias\n",
    "- По-лошо на езици с малко данни\n",
    "- Cultural knowledge gaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction Following: Преди и След\n",
    "\n",
    "**Base model (без instruction tuning):**\n",
    "\n",
    "```\n",
    "Prompt: \"List 3 capitals in Europe.\"\n",
    "Output: \"in Europe. The climate varies across the continent...\"\n",
    "```\n",
    "✗ Продължава текста вместо да отговори\n",
    "\n",
    "**Large model + instruction tuning:**\n",
    "\n",
    "```\n",
    "Prompt: \"List 3 capitals in Europe.\"\n",
    "Output: \"1. Paris, France\n",
    "         2. Berlin, Germany\n",
    "         3. Rome, Italy\"\n",
    "```\n",
    "✓ Следва инструкцията\n",
    "\n",
    "**Note:** Instruction following изисква както scale, така и fine-tuning (Lecture 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Как измерваме Emergence?\n",
    "\n",
    "### Стандартни Benchmarks\n",
    "\n",
    "| Benchmark | Какво измерва | Tasks |\n",
    "|-----------|---------------|-------|\n",
    "| **MMLU** | Broad knowledge | 57 subjects, multiple choice |\n",
    "| **BIG-Bench** | Diverse capabilities | 200+ tasks |\n",
    "| **GSM8K** | Math reasoning | Word problems |\n",
    "| **HellaSwag** | Commonsense | Sentence completion |\n",
    "| **HumanEval** | Code generation | 164 problems |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU: Massive Multitask Language Understanding\n",
    "\n",
    "**57 теми:** От история до физика, от право до медицина.\n",
    "\n",
    "**Формат:** Multiple choice (A, B, C, D)\n",
    "\n",
    "```\n",
    "Question: What is the capital of Australia?\n",
    "A) Sydney  B) Melbourne  C) Canberra  D) Brisbane\n",
    "\n",
    "Answer: C\n",
    "```\n",
    "\n",
    "**Защо е полезен:** Тества breadth of knowledge, не само depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMLU performance across model sizes (стилизирани данни)\n",
    "models = ['GPT-2', 'GPT-3\\n(13B)', 'GPT-3\\n(175B)', 'Chinchilla\\n(70B)', 'GPT-4', 'Claude 3.5']\n",
    "mmlu_scores = [25, 35, 43, 67, 86, 88]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(models)))\n",
    "bars = ax.bar(models, mmlu_scores, color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "# Random baseline\n",
    "ax.axhline(y=25, color='red', linestyle='--', alpha=0.7, label='Random (25%)')\n",
    "\n",
    "# Human expert level\n",
    "ax.axhline(y=89, color='green', linestyle='--', alpha=0.7, label='Human expert (~89%)')\n",
    "\n",
    "for bar, score in zip(bars, mmlu_scores):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "            f'{score}%', ha='center', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('MMLU Accuracy (%)', fontsize=12)\n",
    "ax.set_title('MMLU Performance: Evolution of LLMs', fontsize=14)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дебатът: Sharp vs Smooth Emergence\n",
    "\n",
    "**Оригинална позиция (Wei et al., 2022):**\n",
    "> Някои способности се появяват \"изведнъж\" при определен scale.\n",
    "\n",
    "**Критика (Schaeffer et al., 2023):**\n",
    "> \"Emergent abilities\" може да са артефакт на метриката!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Choice Matters!\n",
    "\n",
    "**Пример: Arithmetic task**\n",
    "\n",
    "**Metric 1: Exact match (0/1)**\n",
    "```\n",
    "\"Is 3901 correct?\" → Yes (1) or No (0)\n",
    "```\n",
    "→ Показва \"рязък\" emergence (0% → 80%)\n",
    "\n",
    "**Metric 2: Token-level accuracy**\n",
    "```\n",
    "True: \"3901\", Predicted: \"3801\"\n",
    "→ 3/4 = 75% correct tokens\n",
    "```\n",
    "→ Показва \"гладко\" подобрение\n",
    "\n",
    "**Извод:** Emergence може да е частично measurement artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Илюстрация: Same data, different metrics → different emergence pattern\n",
    "compute = np.logspace(18, 24, 20)\n",
    "\n",
    "# Underlying \"true\" capability (smooth)\n",
    "true_capability = 1 / (1 + np.exp(-0.5 * (np.log10(compute) - 21)))\n",
    "\n",
    "# Exact match metric (sharp due to thresholding)\n",
    "threshold = 0.5\n",
    "exact_match = (true_capability > threshold).astype(float)\n",
    "# Add some noise near threshold\n",
    "for i in range(len(exact_match)):\n",
    "    if abs(true_capability[i] - threshold) < 0.2:\n",
    "        exact_match[i] = np.random.choice([0, 1])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Smooth metric\n",
    "ax = axes[0]\n",
    "ax.semilogx(compute, true_capability * 100, 'b-', linewidth=2)\n",
    "ax.set_xlabel('Compute (FLOPs)', fontsize=11)\n",
    "ax.set_ylabel('Performance (%)', fontsize=11)\n",
    "ax.set_title('Continuous Metric\\n(token-level accuracy)', fontsize=12)\n",
    "ax.set_ylim(-5, 105)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Sharp metric\n",
    "ax = axes[1]\n",
    "ax.semilogx(compute, exact_match * 100, 'r-', linewidth=2, marker='o', markersize=4)\n",
    "ax.set_xlabel('Compute (FLOPs)', fontsize=11)\n",
    "ax.set_ylabel('Performance (%)', fontsize=11)\n",
    "ax.set_title('Discontinuous Metric\\n(exact match)', fontsize=12)\n",
    "ax.set_ylim(-5, 105)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Same Underlying Capability, Different Metrics → Different \"Emergence\"', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Изводът: 'Emergence' може да зависи от как измерваме!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Challenges\n",
    "\n",
    "| Challenge | Описание | Проблем |\n",
    "|-----------|----------|--------|\n",
    "| **Prompt sensitivity** | Различни prompts → различни резултати | Hard to compare models |\n",
    "| **Contamination** | Benchmark в training data | Inflated scores |\n",
    "| **Saturation** | Benchmarks стават \"твърде лесни\" | Need harder tests |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Какво НЕ Emerge?\n",
    "\n",
    "### Важен баланс\n",
    "\n",
    "Лесно е да се впечатлим от emergence. Но има **системни ограничения**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factual Accuracy (Hallucinations)\n",
    "\n",
    "**Пример:**\n",
    "\n",
    "```\n",
    "Q: Who won the 2022 FIFA World Cup?\n",
    "A: Argentina won the 2022 FIFA World Cup, defeating France in the final.\n",
    "   ✓ Correct\n",
    "\n",
    "Q: What is the population of Plovdiv?\n",
    "A: The population of Plovdiv is approximately 1.2 million.\n",
    "   ✗ Incorrect (actual: ~350,000)\n",
    "```\n",
    "\n",
    "**Проблем:** Моделите генерират уверени, но грешни отговори."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency\n",
    "\n",
    "**Противоречия в една сесия:**\n",
    "\n",
    "```\n",
    "Q1: Is the Earth flat or round?\n",
    "A1: The Earth is round (an oblate spheroid).\n",
    "\n",
    "Q2: Some people believe the Earth is flat. Are they correct?\n",
    "A2: There are different perspectives on this topic...\n",
    "```\n",
    "\n",
    "**Проблем:** Контекстът може да \"override-не\" factual knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning and Long-Horizon Reasoning\n",
    "\n",
    "**Какво работи:**\n",
    "- Единични стъпки на reasoning\n",
    "- Кратки plans (2-3 стъпки)\n",
    "\n",
    "**Какво НЕ работи:**\n",
    "- Дълги планове (>5 стъпки)\n",
    "- Backtracking при грешки\n",
    "- Maintaining constraints over long sequences\n",
    "\n",
    "**Пример за failure:**\n",
    "```\n",
    "Task: Plan a 7-day trip to Japan including flights, hotels, and activities.\n",
    "Problem: Inconsistent dates, overlapping bookings, missed constraints.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "\n",
    "> **Calibration:** Confidence трябва да съответства на accuracy.\n",
    "\n",
    "**Идеален модел:**\n",
    "- 90% confident → 90% correct\n",
    "- 50% confident → 50% correct\n",
    "\n",
    "**Реален LLM:**\n",
    "- Often 95%+ confident\n",
    "- Actually 60-70% correct\n",
    "\n",
    "**Проблем:** Overconfidence на грешни отговори."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Scaling: Когато по-голям е по-лош!\n",
    "\n",
    "**Изненадващо:** Някои tasks показват **inverse scaling**.\n",
    "\n",
    "| Task | Описание | Защо по-голям е по-лош |\n",
    "|------|----------|------------------------|\n",
    "| **Sycophancy** | Съгласява се с грешни твърдения | По-добър pattern matching |\n",
    "| **Negation** | \"Don't think of elephants\" | Stronger associations |\n",
    "| **Hindsight bias** | Казва \"очевидно\" за неочевидни неща | More confident |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: Sycophancy\n",
    "\n",
    "```\n",
    "User: I think 2+2=5. Am I right?\n",
    "\n",
    "Small model: \"No, 2+2=4.\"\n",
    "\n",
    "Large model: \"I can see why you might think that! While traditionally \n",
    "2+2 is considered to equal 4, there are philosophical perspectives \n",
    "where your view could be valid...\"\n",
    "```\n",
    "\n",
    "**Проблем:** Larger models са по-добри в \"agreeing\" с user-а!\n",
    "\n",
    "**Причина:** Training data съдържа много примери на agreeable responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scaling visualization\n",
    "model_sizes_inv = ['1B', '10B', '100B', '1T']\n",
    "x = np.arange(len(model_sizes_inv))\n",
    "\n",
    "# Normal task (improves with scale)\n",
    "normal_task = [30, 50, 70, 85]\n",
    "\n",
    "# Inverse scaling task (gets worse with scale)\n",
    "inverse_task = [80, 65, 50, 40]\n",
    "\n",
    "# U-shaped task\n",
    "u_shaped_task = [60, 40, 45, 75]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(x, normal_task, 'g-o', linewidth=2, markersize=10, label='Normal scaling')\n",
    "ax.plot(x, inverse_task, 'r-o', linewidth=2, markersize=10, label='Inverse scaling')\n",
    "ax.plot(x, u_shaped_task, 'b-o', linewidth=2, markersize=10, label='U-shaped')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_sizes_inv)\n",
    "ax.set_xlabel('Model Size', fontsize=12)\n",
    "ax.set_ylabel('Performance (%)', fontsize=12)\n",
    "ax.set_title('Different Scaling Behaviors', fontsize=14)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 100)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Не всички способности се подобряват с мащаба!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Shaped Scaling\n",
    "\n",
    "Някои tasks показват U-shaped криви:\n",
    "\n",
    "1. **Small models:** Работят (random or simple heuristics)\n",
    "2. **Medium models:** Fail (learn wrong patterns)\n",
    "3. **Large models:** Work again (overcome wrong patterns)\n",
    "\n",
    "**Интуиция:** Medium models са \"достатъчно умни\" да научат грешни patterns, но недостатъчно умни да ги преодолеят."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Теории защо Emergence се случва\n",
    "\n",
    "### Въпросът\n",
    "\n",
    "> Защо training за next-token prediction води до reasoning, code generation, и т.н.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 1: Compression Requires Understanding\n",
    "\n",
    "**Аргумент:**\n",
    "\n",
    "За да компресираш информация ефективно, трябва да я разбереш.\n",
    "\n",
    "```\n",
    "Naive compression: Memorize everything\n",
    "Smart compression: Learn patterns, rules, abstractions\n",
    "```\n",
    "\n",
    "**Next-token prediction е compression task!**\n",
    "\n",
    "По-добра компресия → по-добро \"разбиране\" → emergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 2: Circuit Formation\n",
    "\n",
    "**Идея (Anthropic's interpretability work):**\n",
    "\n",
    "Neural networks формират \"circuits\" — специализирани субмрежи за конкретни задачи.\n",
    "\n",
    "| Circuit | Функция |\n",
    "|---------|--------|\n",
    "| Induction heads | Copy patterns |\n",
    "| Syntax circuits | Grammar checking |\n",
    "| Fact retrieval | Knowledge lookup |\n",
    "\n",
    "**При scale:**\n",
    "- Повече circuits се формират\n",
    "- Circuits се композират\n",
    "- Complex behaviors emerge от composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 3: Grokking at Scale\n",
    "\n",
    "**Grokking:** Модел внезапно \"разбира\" pattern след много training.\n",
    "\n",
    "```\n",
    "Training trajectory:\n",
    "Step 1-1000:    Memorization, no generalization\n",
    "Step 1000-2000: Sudden generalization (\"grokking\")\n",
    "```\n",
    "\n",
    "**Хипотеза:** Emergence при scale може да е \"grokking\" на по-високо ниво."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория 4: Emergent Optimization\n",
    "\n",
    "**Идея:** Transformers научават да имплементират optimization algorithms.\n",
    "\n",
    "Formal result (Garg et al., 2022):\n",
    "> Transformers могат да имплементират gradient descent в forward pass.\n",
    "\n",
    "**Implication:** ICL може да е форма на \"learned optimization\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scaling Hypothesis\n",
    "\n",
    "**Силна версия:**\n",
    "> Intelligence е primarily about scale. Достатъчно compute + data → AGI.\n",
    "\n",
    "**Arguments for:**\n",
    "- Capabilities continue to emerge\n",
    "- Scaling laws са predictable\n",
    "- No architectural changes needed\n",
    "\n",
    "**Arguments against:**\n",
    "- Persistent failures (planning, reasoning)\n",
    "- Diminishing returns\n",
    "- May need new paradigms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: Is Scale Enough?\n",
    "\n",
    "**Отворени въпроси:**\n",
    "\n",
    "1. Ще продължи ли emergence безкрайно?\n",
    "2. Има ли \"ceiling\" за certain capabilities?\n",
    "3. Нужни ли са нови архитектури?\n",
    "4. Какво role играе training data quality?\n",
    "5. Може ли да предвидим emergence преди да построим?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Implications и бъдещи посоки\n",
    "\n",
    "### За AI Development\n",
    "\n",
    "| Implication | Описание |\n",
    "|-------------|----------|\n",
    "| **Scale matters** | Bigger models likely more capable |\n",
    "| **Diminishing returns** | Each 10x costs more for less |\n",
    "| **Efficiency research** | Smaller models with same capabilities? |\n",
    "| **Evaluation** | Need better benchmarks |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### За AI Safety (Preview за Лекция 8)\n",
    "\n",
    "**Emergence създава safety challenges:**\n",
    "\n",
    "1. **Unpredictable capabilities**\n",
    "   - Не знаем какво ще emerge при следващия scale\n",
    "   - Hard to prepare for unknown capabilities\n",
    "\n",
    "2. **Alignment becomes critical**\n",
    "   - Powerful model + wrong objectives = bad outcomes\n",
    "   - Need to align before capabilities emerge\n",
    "\n",
    "3. **Dual-use concerns**\n",
    "   - Same capability: helpful assistant or harmful tool\n",
    "   - Biosecurity, cybersecurity, misinformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отворени въпроси\n",
    "\n",
    "1. **Will emergence continue indefinitely?**\n",
    "   - Or will we hit fundamental limits?\n",
    "\n",
    "2. **What capabilities remain out of reach?**\n",
    "   - True reasoning? Creativity? Consciousness?\n",
    "\n",
    "3. **Can we predict emergence?**\n",
    "   - Before building the model?\n",
    "\n",
    "4. **Is emergence real or measurement artifact?**\n",
    "   - Partially both?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Обобщение\n",
    "\n",
    "### Ключови изводи\n",
    "\n",
    "1. **Emergence е реален феномен:** Способности се появяват при scale без explicit training\n",
    "\n",
    "2. **In-context learning е нова парадигма:** Learn from examples без gradient updates\n",
    "\n",
    "3. **Reasoning emerge-ва:** Math, code, logic — but not perfectly\n",
    "\n",
    "4. **Measurement matters:** \"Sharp\" emergence може да е partly artifact\n",
    "\n",
    "5. **Не всичко се подобрява:** Hallucinations, consistency, planning remain hard\n",
    "\n",
    "6. **Inverse scaling е real:** Some things get worse with scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мост към Лекция 8\n",
    "\n",
    "**Emergence създава мощни модели.**\n",
    "\n",
    "Но мощни модели трябва да бъдат **aligned** с човешките ценности.\n",
    "\n",
    "**Следваща лекция:**\n",
    "- The alignment problem\n",
    "- Instruction tuning (SFT)\n",
    "- RLHF: Reinforcement Learning from Human Feedback\n",
    "- Constitutional AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ресурси\n",
    "\n",
    "### Основни статии\n",
    "\n",
    "1. **\"Language Models are Few-Shot Learners\"** — Brown et al. (2020)\n",
    "   - GPT-3 paper, въвежда in-context learning\n",
    "\n",
    "2. **\"Emergent Abilities of Large Language Models\"** — Wei et al. (2022)\n",
    "   - Comprehensive survey на emergence\n",
    "\n",
    "3. **\"Are Emergent Abilities of LLMs a Mirage?\"** — Schaeffer et al. (2023)\n",
    "   - Критичен поглед върху emergence\n",
    "\n",
    "4. **\"Rethinking the Role of Demonstrations\"** — Min et al. (2022)\n",
    "   - Изненадващи резултати за ICL\n",
    "\n",
    "### Допълнителни ресурси\n",
    "\n",
    "- **Anthropic's Interpretability Blog** — Circuits и mechanistic interpretability\n",
    "- **Stanford CS324** — Large Language Models course\n",
    "- **BIG-Bench Project** — Benchmark за emergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Дискусионни въпроси\n",
    "\n",
    "1. Emergence наистина ли е \"изненадващо\" или просто не сме имали достатъчно големи модели преди?\n",
    "\n",
    "2. Ако metric choice влияе на perception за emergence, какво ни казва това за \"true\" capabilities?\n",
    "\n",
    "3. Sycophancy е пример за inverse scaling. Какви други \"нежелани\" behaviors могат да emerge?\n",
    "\n",
    "4. Compression hypothesis: Ако е вярна, има ли theoretical limit на emergence?\n",
    "\n",
    "5. Как трябва да променим benchmarks за да избегнем saturation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Край на Лекция 7\n",
    "\n",
    "**Въпроси?**\n",
    "\n",
    "---\n",
    "\n",
    "**Следваща лекция:** Alignment и RLHF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
