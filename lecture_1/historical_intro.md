# Кратка история на изкуствения интелект и машинното самообучение

## Раждането на идеята (1940–1950)

Идеята за „мислеща машина" е стара колкото човешкото въображение, но научният ѝ фундамент се появява едва през XX век. През 1943 г. невролозите Уорън Маккълок и Уолтър Питс публикуват първия математически модел на изкуствен неврон — опростена имитация на биологичния неврон в мозъка. Моделът им показва, че логически операции могат да се изчисляват от прости свързани единици.

През 1950 г. Алан Тюринг задава въпроса: „Могат ли машините да мислят?" В статията си *Computing Machinery and Intelligence* той предлага знаменития „тест на Тюринг" — ако човек не може да различи машина от друг човек в текстов разговор, машината може да се счита за интелигентна. Този въпрос остава централен и днес.

## Първите стъпки (1950–1970)

Терминът „изкуствен интелект" е въведен през 1956 г. на конференция в Дартмут колеж. Организаторите — Джон Маккарти, Марвин Мински, Клод Шанън и Натаниел Рочестър — събират изследователи около амбициозната цел: да създадат машини, способни на разумно поведение.

Първите десетилетия носят ентусиазъм. Програми като ELIZA (1966) симулират психотерапевт чрез прости текстови шаблони — и макар да нямат истинско „разбиране", изненадват хората с илюзията за разговор. Същевременно се появяват експертни системи, базирани на ръчно въведени правила.

Но границите бързо стават ясни. Ръчното програмиране на знания се оказва непрактично за сложни задачи. Липсват данни и изчислителна мощ. Следват периоди на разочарование, известни като „AI зими".

## Статистическият обрат (1980–2000)

През 80-те и 90-те години AI се отдалечава от символните системи и се насочва към статистически методи. Вместо да програмират правила изрично, изследователите започват да обучават модели върху данни.

За езика това е революция. N-грам модели предсказват вероятността за следващата дума, базирайки се на предходните. Макар примитивни, тези модели работят изненадващо добре за машинен превод и разпознаване на реч. Появяват се и първите системи за автоматична класификация на текст — спам филтри, категоризация на новини.

Ключова идея от този период: **нека данните говорят**. Вместо човек да описва какво е „спам", моделът се учи от примери.

## Епохата на невронните мрежи (2010–днес)

През 2012 г. настъпва преломен момент. Дълбока невронна мрежа печели състезанието ImageNet с огромна преднина пред конкурентите. Успехът се дължи на три фактора: повече данни, по-мощни GPU процесори и нови алгоритми за обучение.

За обработката на естествен език революцията идва през 2017 г. с архитектурата Transformer, представена в статията *Attention Is All You Need*. За разлика от предишните модели, които четат текст дума по дума, Transformer може да „гледа" цялото изречение наведнъж и да се фокусира върху най-важните части. Това е основата на днешните големи езикови модели.

## Ерата на LLM (2020–днес)

GPT-3 (2020), ChatGPT (2022), GPT-4, Claude, Gemini — тези модели са трениран върху огромни текстови масиви и демонстрират способности, които изненадват дори създателите им. Те превеждат, обобщават, пишат код, отговарят на въпроси и водят разговори.

Зад впечатляващите способности стои простa идея: **предсказване на следващата дума**. Модел, трениран да продължава текст убедително, се научава на граматика, факти, разсъждения и дори известна степен на „здрав разум" — всичко извлечено от данните.

---

## От история към практика

Този курс следва историческата логика на развитието:

1. **Лекция 1** започва с основите — какво е машинно самообучение, как формулираме задачи, как оценяваме модели.

2. **Лекции 2–4** покриват фундаменталните градивни блокове: представяне на думи, токенизация, невронни мрежи.

3. **Лекции 5–6** навлизат в съвременните архитектури: Transformer, предварително обучение, scaling laws.

4. **Лекции 7–12** изследват способностите на съвременните модели и как да ги използваме: emergent abilities, alignment, локални модели, prompting, RAG, агенти.

Всяка лекция надгражда предишните. Ще видите как простите идеи от 1940-те — математическият неврон на Маккълок и Питс — еволюират до модели с милиарди параметри, които днес променят начина, по който работим с текст.

---

*„Тези, които не помнят историята, са обречени да я повтарят."*
*— Джордж Сантаяна*

Но в машинното самообучение историята си заслужава да бъде повторена — защото всяка стъпка води към следващата.
